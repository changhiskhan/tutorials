---
title: Episode 1
slug: /docs/nlp-tutorial-L1
tags: [orchestration]
sidebar_label: Episode 1
id: nlp-tutorial-L1
description: A tutorial that uses Keras, Scikit-Learn, and Metaflow to operationalize a machine learning workflow.
category: tutorials
---


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! Instead, edit the notebook w/the location & name as this file. -->

### Setup Instructions

If you haven't done so, please follow the [setup instructions](./nlp-tutorial-setup) to prepare your environment.  This tutorial will be referencing this [Notebook](https://github.com/outerbounds/tutorials/blob/main/nlp/nlp-1.ipynb).

#### What You Will Learn

At the end of this lesson you will become familiar with the dataset and the baseline relevant to the business problem we want to solve.

#### Background

We are going to build a model that does classifies customer reviews as positive or negative sentiment, using the [Women's E-Commerce Clothing Reviews Dataset](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews). Here is what the data looks like:


```
import pandas as pd
df = pd.read_parquet('train.parquet')
print(f'num of rows: {df.shape[0]}')
```

<CodeOutputBlock lang="">

```
    num of rows: 20377
```

</CodeOutputBlock>

The data is stored in a [parquet file](https://parquet.apache.org/), which is a framework agnostic way of storing data that you are likely to encounter in the wild.  It works seamlessly with pandas, and is a format that is commonly available if your data is already in a database. 


```
df.head()
```
    
<HTMLOutputBlock >




```html
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>labels</th>
      <th>review</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>Odd fit: I wanted to love this sweater but the...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>Very comfy dress: The quality and material of ...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>Fits nicely but fabric a bit thin: I ordered t...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>Great fit: Love these jeans, fit and style... ...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>Stretches out, washes poorly. wish i could ret...</td>
    </tr>
  </tbody>
</table>
</div>
```



</HTMLOutputBlock>

Before we begin training a model, it is useful to set a baseline.  One such baseline is the majority-class classifier, which measures what happens when we label all of our examples with the majority class.  We can then calculate our performance metrics by using this baseline model, which in this case is [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) and the [area under the ROC curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html):


```
from sklearn.metrics import accuracy_score, roc_auc_score

valdf = pd.read_parquet('valid.parquet')
baseline_predictions = [1] * valdf.shape[0]
base_acc = accuracy_score(valdf.labels, baseline_predictions)
base_rocauc = roc_auc_score(valdf.labels, baseline_predictions)

print(f'Baseline Accuracy: {base_acc:.3f}\nBaseline AUC: {base_rocauc}')
```

<CodeOutputBlock lang="">

```
    Baseline Accuracy: 0.773
    Baseline AUC: 0.5
```

</CodeOutputBlock>

Now that we understand the dataset and the problem a bit more, we can now start building our model.  We will draw upon machine learning techniques from [natural language processing](https://en.wikipedia.org/wiki/Natural_language_processing) to see if we can train an algorithm to predict the sentiment of these fashion reviews.
