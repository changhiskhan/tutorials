{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d8c49a7a-e52b-42c7-bdaf-7d7db37e0b12",
   "metadata": {},
   "source": [
    "---\n",
    "title: Episode 2\n",
    "slug: /docs/nlp-tutorial-L2\n",
    "tags: [orchestration]\n",
    "sidebar_label: Episode 2\n",
    "id: nlp-tutorial-L2\n",
    "description: A tutorial that uses Keras, Scikit-Learn, and Metaflow to operationalize a machine learning workflow.\n",
    "category: tutorials\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d65b4d-372a-42ce-b7ec-344ed8ff1072",
   "metadata": {},
   "source": [
    "### Setup Instructions\n",
    "\n",
    "If you haven't done so, please follow the [setup instructions](./nlp-tutorial-setup) to prepare your environment.  This tutorial will reference [model.py](https://github.com/outerbounds/tutorials/blob/main/nlp/model.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22395431-e23d-422a-9e85-5d617f66fc82",
   "metadata": {},
   "source": [
    "#### What You Will Learn\n",
    "At the end of this lesson, you will:\n",
    "    \n",
    "* Learn how to build a simple NLP model using Tensorflow and scikit-learn to classify fashion reviews\n",
    "* Learn how to set up your model so that it can be easily used in Metaflow"
   ]
  },
  {
   "cell_type": "raw",
   "id": "373dd28e-194c-4135-8092-16dca87f5edc",
   "metadata": {},
   "source": [
    "<Wrapper>\n",
    "<Highlight>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298d9a86-f982-4ad2-bc25-73171b5ac3c0",
   "metadata": {},
   "source": [
    "Now itâ€™s time to build our ML model.  We are going to define our model in a separate file with a custom class called `Nbow_Model`.  The model contains two subcomponents: the count vectorizer for preprocessing and the model.  This class facilitates combining these two components together so that we don't have to deal with them separately."
   ]
  },
  {
   "cell_type": "raw",
   "id": "07d9cea9-9fd0-4ecb-8dee-f85bdb668829",
   "metadata": {},
   "source": [
    "</Highlight>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67358c68-f35d-4209-bece-9ecef9f4e49f",
   "metadata": {},
   "source": [
    "Here an exaplanation of the various methods in this model:\n",
    "\n",
    "1. `__init__`: this initializes the count vectorizer, a preprocessor that counts the tokens in the text and a nueral network to do the modeling.\n",
    "2. `fit`:  when we call `fit`, we first fit the count vectorizer, followed by the model. \n",
    "3.  `predict`: similarly, when we call `predict`, we need to transform the data with the count vectorizer before making predictions.\n",
    "4. `eval_acc`: calculates model accuracy given a dataset and labels\n",
    "5. `eval_rocauc`: calculates the area under the roc curve given a dataset and labels\n",
    "6. `model_dict`: This exposes of a dictionary that has two components that form this model, the count vectorizer and the nueral network.  We will use this to serialize the model's data into Metaflow. \n",
    "7.  `from_dict`: this allows you to instantiate a NbowModel from a `model_dict` which is useful for de-serializing data in Metaflow.\n",
    "\n",
    "Anytime you create your own model library or define models in custom classes, we recommend explicitly defining how you will serialize and load the model.  This will minimize the chances that things will break as your model code changes by giving you the ability to make sure any new versions of your code are backward compatible on how to load your model or allow you to deal with serialization/de-serialization accordingly in a way that is transparent to you.  This is the purpose of the `from_dict` method and `model_dict` property.  \n",
    "\n",
    "For Metaflow, it is very convenient if you have an interface that allows you to save model information that is pickleable, as that is how Metaflow saves data.  That is the purpose of `model_dict` and `from_dict`: they allow saving and retrieving data from a pickleable data structure."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2c7c2e2-8fe6-4fd6-92ff-a5ed05a2a88c",
   "metadata": {},
   "source": [
    "<RHS>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdfeb3a-701f-4bb8-abd2-a4bdf4867288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers, regularizers\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class NbowModel():\n",
    "    def __init__(self, vocab_sz):\n",
    "        self.vocab_sz = vocab_sz\n",
    "        # Instantiate the CountVectorizer\n",
    "        self.cv = CountVectorizer(min_df=.005, max_df = .75, stop_words='english', strip_accents='ascii', max_features=self.vocab_sz)\n",
    "        \n",
    "        # Define the keras model\n",
    "        inputs = tf.keras.Input(shape=(self.vocab_sz,), name='Input')\n",
    "        x = layers.Dropout(0.10)(inputs)\n",
    "        x = layers.Dense(15, activation=\"relu\", kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4))(x)\n",
    "        predictions = layers.Dense(1, activation=\"sigmoid\",)(x)\n",
    "        self.model = tf.keras.Model(inputs, predictions)\n",
    "        opt = optimizers.Adam(learning_rate=0.002)\n",
    "        self.model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        res = self.cv.fit_transform(X).toarray()\n",
    "        self.model.fit(x=res, y=y, batch_size=32, epochs=10, validation_split=.2)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        res = self.cv.transform(X).toarray()\n",
    "        return self.model.predict(res)\n",
    "    \n",
    "    def eval_acc(self, X, labels, threshold=.5):\n",
    "        return accuracy_score(labels, self.predict(X) > threshold)\n",
    "    \n",
    "    def eval_rocauc(self, X, labels):\n",
    "        return roc_auc_score(labels,  self.predict(X))\n",
    "\n",
    "    @property\n",
    "    def model_dict(self): return {'vectorizer':self.cv, 'model': self.model}\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, model_dict):\n",
    "        \"Get Model from dictionary\"\n",
    "        nbow_model = cls(len(model_dict['vectorizer'].vocabulary_))\n",
    "        nbow_model.model = model_dict['model']\n",
    "        nbow_model.cv = model_dict['vectorizer']\n",
    "        return nbow_model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d51f228-098c-43f3-a8d2-18d8c8b16754",
   "metadata": {},
   "source": [
    "</RHS>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b13fce-f64f-45db-a43d-4098540c084f",
   "metadata": {},
   "source": [
    "Next, let's import the `NbowModel` and train it on this dataset.  The purpose of doing this is to make sure the code works as we expect before using Metaflow.  For this example, we will set our `vocab_sz = 750`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad60de67-222b-4c28-8ec1-502845f17163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.3619 - accuracy: 0.8447 - val_loss: 0.3018 - val_accuracy: 0.8707\n",
      "Epoch 2/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2945 - accuracy: 0.8797 - val_loss: 0.2923 - val_accuracy: 0.8776\n",
      "Epoch 3/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2837 - accuracy: 0.8855 - val_loss: 0.2949 - val_accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2708 - accuracy: 0.8925 - val_loss: 0.3075 - val_accuracy: 0.8744\n",
      "Epoch 5/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2623 - accuracy: 0.8982 - val_loss: 0.3036 - val_accuracy: 0.8795\n",
      "Epoch 6/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2530 - accuracy: 0.9043 - val_loss: 0.3052 - val_accuracy: 0.8756\n",
      "Epoch 7/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2441 - accuracy: 0.9104 - val_loss: 0.3104 - val_accuracy: 0.8766\n",
      "Epoch 8/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2356 - accuracy: 0.9158 - val_loss: 0.3193 - val_accuracy: 0.8744\n",
      "Epoch 9/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2254 - accuracy: 0.9203 - val_loss: 0.3316 - val_accuracy: 0.8697\n",
      "Epoch 10/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2145 - accuracy: 0.9261 - val_loss: 0.3330 - val_accuracy: 0.8734\n"
     ]
    }
   ],
   "source": [
    "#notest\n",
    "from model import NbowModel\n",
    "model = NbowModel(vocab_sz=750)\n",
    "model.fit(X=df['review'], y=df['labels'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6d26672-e58d-404a-b063-e87019210daa",
   "metadata": {},
   "source": [
    "</Wrapper>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da3c613-4238-4818-92c7-5c531f4e5f6a",
   "metadata": {},
   "source": [
    "Next, we can evaluate our model on the validation set as well, using the built-in evaluation methods we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16cec94-4a7e-4839-b8f5-d86620c43279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.875\n",
      "Baseline AUC: 0.914\n"
     ]
    }
   ],
   "source": [
    "#notest\n",
    "model_acc = model.eval_acc(valdf['review'], valdf['labels'])\n",
    "model_rocauc = model.eval_rocauc(valdf['review'], valdf['labels'])\n",
    "\n",
    "print(f'Baseline Accuracy: {model_acc:.3f}\\nBaseline AUC: {model_rocauc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b757370c-a330-4397-a09c-31b485a24185",
   "metadata": {},
   "source": [
    "Great! This is an improvement upon our baseline!  Now we have set up what we need to start using Metaflow.  In the next lesson, we are going to operationalize the steps we manually performed here into a Flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69543839-7a29-4482-9adf-00bb940c954e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
