---
title: Episode 5
slug: /docs/nlp-tutorial-L5
tags: [orchestration]
sidebar_label: Episode 5
id: nlp-tutorial-L5
description: A tutorial that uses Keras, Scikit-Learn, and Metaflow to operationalize a machine learning workflow.
category: tutorials
---


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! Instead, edit the notebook w/the location & name as this file. -->

### Setup Instructions

If you haven't done so, please follow the [setup instructions](./nlp-tutorial-setup) to prepare your environment.  This tutorial will reference the python script [nlpflow.py](https://github.com/outerbounds/tutorials/blob/main/nlp/nlpflow.py).

#### What You Will Learn
At the end of this lesson, you will:
    
* Learn how to collaborate on and organize flows with tagging.
* Learn design patterns for testing your models.

In Lesson 4, you saw how we trained a model and compared it to a baseline.  However, what if your model is worse than the baseline?  Is there a way to manage this situation programmatically? An important Metaflow feature that can enable this is [Tagging](https://outerbounds.com/blog/five-ways-to-use-the-new-metaflow-tags).  Tagging allows you to categorize and organize flows, which we can use to mark certain models as "production candidates.‚Äù

### <NumberHeading number={1}>What is Tagging</NumberHeading>


Tags allow you to express opinions about results of your and your colleagues' work, and, importantly, change those assessments at any time. In contrast to runs and artifacts that represent immutable facts (history shouldn't be rewritten), the way how you interpret those facts may change over time, which is reflected in tags.  This makes tags ideal for managing which models are promoted to the next step in your modeling workflow.

You can add a tag to a flow with only a few lines of code.  Below is a snippet of code we will use to add tags in our flow:

```python
from metaflow import Flow, current
run = Flow(current.flow_name)[current.run_id]
run.add_tag('deployment_candidate')
```

<Wrapper>

### <NumberHeading number={2}>Write A Flow</NumberHeading>

<Highlight>


In this flow, we modify our `end` step to apply the tag `deployment_candidate` if our model passes two tests: (1) a baseline (2) and a smoke test.

</Highlight>


Concretely, we will add the following to the `end` step:

1. **A smoke test** that tests that the model is performing correctly against very easy examples that it should not be getting wrong.  A smoke test is a lightweight way to catch unexpected behaviors in your model, even if your model is beating the baseline. 
2. **A comparison of the model with the baseline**. We are going to check if our model's AUC score is better than the baseline.  There are more advanced variations on this technique, including using other models for baselines, or requiring that your model performs better than the baseline by a specific margin.  We leave these variations as an excercise for the reader.
3. **Add a tag** if our model passes the smoke test and beats the baseline.

<RHS>



```py title="nlpflow.py"
from metaflow import FlowSpec, step, Flow, current

class NLPFlow(FlowSpec):
        
    @step
    def start(self):
        "Read the data"
        import pandas as pd
        self.df = pd.read_parquet('train.parquet')
        self.valdf = pd.read_parquet('valid.parquet')
        print(f'num of rows: {self.df.shape[0]}')
        self.next(self.baseline, self.train)

    @step
    def baseline(self):
        "Compute the baseline"
        from sklearn.metrics import accuracy_score, roc_auc_score
        baseline_predictions = [1] * self.valdf.shape[0]
        self.base_acc = accuracy_score(self.valdf.labels, baseline_predictions)
        self.base_rocauc = roc_auc_score(self.valdf.labels, baseline_predictions)
        self.next(self.join)

    @step
    def train(self):
        "Train the model"
        from model import NbowModel
        model = NbowModel(vocab_sz=750)
        model.fit(X=self.df['review'], y=self.df['labels'])
        self.model_dict = model.model_dict #save model
        self.next(self.join)
        
    @step
    def join(self, inputs):
        "Compare the model results with the baseline."
        import pandas as pd
        from model import NbowModel
        self.model_dict = inputs.train.model_dict
        self.train_df = inputs.train.df
        self.val_df = inputs.baseline.valdf
        self.base_rocauc = inputs.baseline.base_rocauc
        self.base_acc = inputs.baseline.base_acc
        model = NbowModel.from_dict(self.model_dict)
        
        self.model_acc = model.eval_acc(X=self.val_df['review'], labels=self.val_df['labels'])
        self.model_rocauc = model.eval_rocauc(X=self.val_df['review'], labels=self.val_df['labels'])
        
        print(f'Baseline Acccuracy: {self.base_acc:.2%}')
        print(f'Baseline AUC: {self.base_rocauc:.2}')
        print(f'Model Acccuracy: {self.model_acc:.2%}')
        print(f'Model AUC: {self.model_rocauc:.2}')
        self.next(self.end)
        
    @step
    def end(self):
        "Tags model as a deployment candidate if it beats the baseline and passes smoke tests."
        from model import NbowModel
        model = NbowModel.from_dict(self.model_dict)
        
        self.beats_baseline = self.model_rocauc > self.base_rocauc
        print(f'Model beats baseline (T/F): {self.beats_baseline}')
        #smoke test to make sure model is doing the right thing on obvious examples.
        _tst_reviews = ["poor fit its baggy in places where it isn't supposed to be.",
                        "love it, very high quality and great value"]
        _tst_preds = model.predict(_tst_reviews)
        self.passed_smoke_test = _tst_preds[0][0] < .5 and _tst_preds[1][0] > .5
        print(f'Model passed smoke test (T/F): {self.passed_smoke_test}')
        
        if self.beats_baseline and self.passed_smoke_test:
            run = Flow(current.flow_name)[current.run_id]
            run.add_tag('deployment_candidate')
        

if __name__ == '__main__':
    NLPFlow()
```

</RHS>


### <NumberHeading number={3}>Run Flow</NumberHeading>



```bash
python nlpflow.py run
```

<CodeOutputBlock lang="bash">

```
     Workflow starting (run-id 1660241139962368):
     [1660241139962368/start/1 (pid 31012)] Task is starting.
     [1660241139962368/start/1 (pid 31012)] num of rows: 20377
     [1660241139962368/start/1 (pid 31012)] Task finished successfully.
     [1660241139962368/baseline/2 (pid 31016)] Task is starting.
     [1660241139962368/train/3 (pid 31017)] Task is starting.
     [1660241139962368/baseline/2 (pid 31016)] Task finished successfully.
     [1660241139962368/train/3 (pid 31017)] 783: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2
     [1660241139962368/train/3 (pid 31017)] Epoch 1/10
    510/510 [==============================] - 1s 1ms/step - loss: 0.3461 - accuracy: 0.8533 - val_loss: 0.2959 - val_accuracy: 0.877352 - loss: 0.6965 - accuracy: 0.46
     [1660241139962368/train/3 (pid 31017)] Epoch 2/10
    510/510 [==============================] - 0s 954us/step - loss: 0.2932 - accuracy: 0.8825 - val_loss: 0.2947 - val_accuracy: 0.8768 loss: 0.2771 - accuracy: 0.87
     [1660241139962368/train/3 (pid 31017)] Epoch 3/10
    510/510 [==============================] - 0s 959us/step - loss: 0.2804 - accuracy: 0.8904 - val_loss: 0.3022 - val_accuracy: 0.8778 loss: 0.3165 - accuracy: 0.84
     [1660241139962368/train/3 (pid 31017)] Epoch 4/10
    510/510 [==============================] - 0s 956us/step - loss: 0.2685 - accuracy: 0.8951 - val_loss: 0.3038 - val_accuracy: 0.8751 loss: 0.1903 - accuracy: 0.96
     [1660241139962368/train/3 (pid 31017)] Epoch 5/10
    510/510 [==============================] - 0s 951us/step - loss: 0.2613 - accuracy: 0.8998 - val_loss: 0.3039 - val_accuracy: 0.8773 loss: 0.2267 - accuracy: 0.93
     [1660241139962368/train/3 (pid 31017)] Epoch 6/10
    510/510 [==============================] - 0s 965us/step - loss: 0.2564 - accuracy: 0.9029 - val_loss: 0.3055 - val_accuracy: 0.8759 loss: 0.1808 - accuracy: 0.93
     [1660241139962368/train/3 (pid 31017)] Epoch 7/10
    510/510 [==============================] - 1s 992us/step - loss: 0.2453 - accuracy: 0.9093 - val_loss: 0.3162 - val_accuracy: 0.8705 loss: 0.1655 - accuracy: 0.9
     [1660241139962368/train/3 (pid 31017)] Epoch 8/10
    510/510 [==============================] - 1s 989us/step - loss: 0.2342 - accuracy: 0.9166 - val_loss: 0.3215 - val_accuracy: 0.8714 loss: 0.1503 - accuracy: 1.00
     [1660241139962368/train/3 (pid 31017)] Epoch 9/10
    510/510 [==============================] - 0s 954us/step - loss: 0.2259 - accuracy: 0.9201 - val_loss: 0.3308 - val_accuracy: 0.8687 loss: 0.1529 - accuracy: 0.96
     [1660241139962368/train/3 (pid 31017)] Epoch 10/10
    510/510 [==============================] - 0s 957us/step - loss: 0.2184 - accuracy: 0.9229 - val_loss: 0.3387 - val_accuracy: 0.8724 loss: 0.2147 - accuracy: 0.93
     [1660241139962368/train/3 (pid 31017)] To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
     [1660241139962368/train/3 (pid 31017)] 337: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
     [1660241139962368/train/3 (pid 31017)] Task finished successfully.
     [1660241139962368/join/4 (pid 31024)] Task is starting.
     [1660241139962368/join/4 (pid 31024)] 745: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2
     [1660241139962368/join/4 (pid 31024)] Baseline Acccuracy: 77.30%
     [1660241139962368/join/4 (pid 31024)] To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
     [1660241139962368/join/4 (pid 31024)] 312: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
     [1660241139962368/join/4 (pid 31024)] Baseline AUC: 0.5
     [1660241139962368/join/4 (pid 31024)] Model Acccuracy: 87.28%
     [1660241139962368/join/4 (pid 31024)] Model AUC: 0.91
     [1660241139962368/join/4 (pid 31024)] Task finished successfully.
     [1660241139962368/end/5 (pid 31028)] Task is starting.
     [1660241139962368/end/5 (pid 31028)] 974: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2
     [1660241139962368/end/5 (pid 31028)] Model beats baseline (T/F): True
     [1660241139962368/end/5 (pid 31028)] Model passed smoke test (T/F): True
     [1660241139962368/end/5 (pid 31028)] To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
     [1660241139962368/end/5 (pid 31028)] 732: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
     [1660241139962368/end/5 (pid 31028)] Task finished successfully.
     Done!
```

</CodeOutputBlock>

</Wrapper>


### Next Steps

Now that we have tagged our model if it meets our minimum standards, we are now ready to use this model in downstream workflows.  In the next lesson, we will explore different ways you can utilize the model you have trained.


