{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d8c49a7a-e52b-42c7-bdaf-7d7db37e0b12",
   "metadata": {},
   "source": [
    "---\n",
    "title: Natural Language Processing - Episode 5\n",
    "slug: /docs/nlp-tutorial-L5/\n",
    "tags: [dag, modeling, tagging, nlp]\n",
    "sidebar_label: Evaluate your Model\n",
    "id: nlp-tutorial-L5\n",
    "pagination_next: tutorials/nbs/nlp/nlp-tutorial-L6\n",
    "pagination_prev: tutorials/nbs/nlp/nlp-tutorial-L4\n",
    "description: A tutorial that uses Keras, Scikit-Learn, and Metaflow to operationalize a machine learning workflow.\n",
    "category: data science\n",
    "hide_table_of_contents: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f6f229-fe17-4faa-a491-9c00cf81398e",
   "metadata": {},
   "source": [
    "This episode will reference the Python script [nlpflow.py](https://github.com/outerbounds/tutorials/blob/main/nlp/nlpflow.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df04b2b-eab2-49ac-a591-9b43f39a4aaa",
   "metadata": {},
   "source": [
    "In [the previous episode](/docs/nlp-tutorial-L4/), you saw how we trained a model and compared it to a baseline.  However, what if your model is worse than the baseline?  Is there a way to manage this situation programmatically? An important Metaflow feature that can enable this is [tagging](https://outerbounds.com/blog/five-ways-to-use-the-new-metaflow-tags).  Tagging allows you to categorize and organize flows, which we can use to mark certain models as \"production candidates.‚Äù \n",
    "At the end of this lesson, you will be able to:\n",
    "* Collaborate on and organize flows with tagging.\n",
    "* Implement common design patterns for testing machine learning models."
   ]
  },
  {
   "cell_type": "raw",
   "id": "67acad84-46fb-4f73-b6d0-73eb19bc73f5",
   "metadata": {},
   "source": [
    "### <NumberHeading number={1}>What is Tagging?</NumberHeading>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359b29d2-e7d3-472f-93b3-3e9d56ff6909",
   "metadata": {},
   "source": [
    "Tags allow you to express opinions about results of your and your colleagues' work, and, importantly, change those assessments at any time. In contrast to runs and artifacts that represent immutable facts (history shouldn't be rewritten), the way how you interpret those facts may change over time, which is reflected in tags.  This makes tags ideal for managing which models are promoted to the next step in your modeling workflow.\n",
    "\n",
    "You can add a tag to a flow with only a few lines of code.  Below is a snippet of code we will use to add tags in our flow:\n",
    "\n",
    "```python\n",
    "from metaflow import Flow, current\n",
    "run = Flow(current.flow_name)[current.run_id]\n",
    "run.add_tag('deployment_candidate')\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "id": "678243b6-72ad-45b5-90df-788af715180c",
   "metadata": {},
   "source": [
    "### <NumberHeading number={2}>Write a Flow</NumberHeading>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1759df-3122-4ac6-b23c-8ae07a8386b6",
   "metadata": {},
   "source": [
    "In this flow, we modify our `end` step to apply the tag `deployment_candidate` if our model passes two tests: (1) a baseline (2) and a smoke test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f9c8bd-2a6e-41da-99cd-563dfe53f3e2",
   "metadata": {},
   "source": [
    "Concretely, we will add the following to the `end` step:\n",
    "\n",
    "1. **A smoke test** that tests that the model is performing correctly against very easy examples that it should not be getting wrong.  A smoke test is a lightweight way to catch unexpected behaviors in your model, even if your model is beating the baseline. \n",
    "2. **A comparison of the model with the baseline**. We are going to check if our model's AUC score is better than the baseline.  There are more advanced variations on this technique, including using other models for baselines, or requiring that your model performs better than the baseline by a specific margin.  We leave these variations as an excercise for the reader.\n",
    "3. **Add a tag** if our model passes the smoke test and beats the baseline.\n",
    "\n",
    "![](/assets/nlp-tutorial-NLPFlow.png)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88cf1b61-05fd-411c-bc5d-bdad76f77c2b",
   "metadata": {},
   "source": [
    "<CodeHeight height=\"75vh\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d963d32-b173-40fa-abdd-716dbed09319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting nlpflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile nlpflow.py\n",
    "\n",
    "from metaflow import FlowSpec, step, Flow, current\n",
    "\n",
    "class NLPFlow(FlowSpec):\n",
    "        \n",
    "    @step\n",
    "    def start(self):\n",
    "        \"Read the data\"\n",
    "        import pandas as pd\n",
    "        self.df = pd.read_parquet('train.parquet')\n",
    "        self.valdf = pd.read_parquet('valid.parquet')\n",
    "        print(f'num of rows: {self.df.shape[0]}')\n",
    "        self.next(self.baseline, self.train)\n",
    "\n",
    "    @step\n",
    "    def baseline(self):\n",
    "        \"Compute the baseline\"\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "        baseline_predictions = [1] * self.valdf.shape[0]\n",
    "        self.base_acc = accuracy_score(\n",
    "            self.valdf.labels, baseline_predictions)\n",
    "        self.base_rocauc = roc_auc_score(\n",
    "            self.valdf.labels, baseline_predictions)\n",
    "        self.next(self.join)\n",
    "\n",
    "    @step\n",
    "    def train(self):\n",
    "        \"Train the model\"\n",
    "        from model import NbowModel\n",
    "        model = NbowModel(vocab_sz=750)\n",
    "        model.fit(X=self.df['review'], y=self.df['labels'])\n",
    "        self.model_dict = model.model_dict #save model\n",
    "        self.next(self.join)\n",
    "        \n",
    "    @step\n",
    "    def join(self, inputs):\n",
    "        \"Compare the model results with the baseline.\"\n",
    "        import pandas as pd\n",
    "        from model import NbowModel\n",
    "        self.model_dict = inputs.train.model_dict\n",
    "        self.train_df = inputs.train.df\n",
    "        self.val_df = inputs.baseline.valdf\n",
    "        self.base_rocauc = inputs.baseline.base_rocauc\n",
    "        self.base_acc = inputs.baseline.base_acc\n",
    "        model = NbowModel.from_dict(self.model_dict)\n",
    "        \n",
    "        self.model_acc = model.eval_acc(\n",
    "            X=self.val_df['review'], labels=self.val_df['labels'])\n",
    "        self.model_rocauc = model.eval_rocauc(\n",
    "            X=self.val_df['review'], labels=self.val_df['labels'])\n",
    "        \n",
    "        print(f'Baseline Acccuracy: {self.base_acc:.2%}')\n",
    "        print(f'Baseline AUC: {self.base_rocauc:.2}')\n",
    "        print(f'Model Acccuracy: {self.model_acc:.2%}')\n",
    "        print(f'Model AUC: {self.model_rocauc:.2}')\n",
    "        self.next(self.end)\n",
    "        \n",
    "    @step\n",
    "    def end(self):\n",
    "        \"\"\"Tags model as a deployment candidate\n",
    "           if it beats the baseline and passes smoke tests.\"\"\"\n",
    "        from model import NbowModel\n",
    "        model = NbowModel.from_dict(self.model_dict)\n",
    "        \n",
    "        self.beats_baseline = self.model_rocauc > self.base_rocauc\n",
    "        print(f'Model beats baseline (T/F): {self.beats_baseline}')\n",
    "        #smoke test to make sure model does the right thing.\n",
    "        _tst_reviews = [\n",
    "            \"poor fit its baggy in places where it isn't supposed to be.\",\n",
    "            \"love it, very high quality and great value\"\n",
    "        ]\n",
    "        _tst_preds = model.predict(_tst_reviews)\n",
    "        check_1 = _tst_preds[0][0] < .5\n",
    "        check_2 = _tst_preds[1][0] > .5\n",
    "        self.passed_smoke_test = check_1 and check_2\n",
    "        msg = 'Model passed smoke test (T/F): {}'\n",
    "        print(msg.format(self.passed_smoke_test))\n",
    "        \n",
    "        if self.beats_baseline and self.passed_smoke_test:\n",
    "            run = Flow(current.flow_name)[current.run_id]\n",
    "            run.add_tag('deployment_candidate')\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    NLPFlow()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57f0e1a2-6931-44ac-b0fe-b8211b55393e",
   "metadata": {},
   "source": [
    "</CodeHeight>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3728a897-9ecd-4e2b-b58f-492b25f02b7c",
   "metadata": {},
   "source": [
    "### <NumberHeading number={3}>Run the Flow</NumberHeading>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7126fad4-3299-4b4d-946e-9b3bdf16f1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.7.8\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mNLPFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:eddie\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-09-09 19:17:50.420 \u001b[0m\u001b[1mWorkflow starting (run-id 1662769070414351):\u001b[0m\n",
      "\u001b[35m2022-09-09 19:17:50.425 \u001b[0m\u001b[32m[1662769070414351/start/1 (pid 42550)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-09-09 19:17:50.974 \u001b[0m\u001b[32m[1662769070414351/start/1 (pid 42550)] \u001b[0m\u001b[22mnum of rows: 20377\u001b[0m\n",
      "\u001b[35m2022-09-09 19:17:51.182 \u001b[0m\u001b[32m[1662769070414351/start/1 (pid 42550)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-09-09 19:17:51.187 \u001b[0m\u001b[32m[1662769070414351/baseline/2 (pid 42553)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-09-09 19:17:51.191 \u001b[0m\u001b[32m[1662769070414351/train/3 (pid 42554)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-09-09 19:17:52.036 \u001b[0m\u001b[32m[1662769070414351/baseline/2 (pid 42553)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-09-09 19:17:53.684 \u001b[0m\u001b[32m[1662769070414351/train/3 (pid 42554)] \u001b[0m\u001b[22m2022-09-09 19:17:53.684411: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\u001b[0m\n",
      "\u001b[35m2022-09-09 19:17:53.691 \u001b[0m\u001b[32m[1662769070414351/train/3 (pid 42554)] \u001b[0m\u001b[22mEpoch 1/10\u001b[0m\n",
      "510/510 [==============================] - 1s 806us/step - loss: 0.3562 - accuracy: 0.8500 - val_loss: 0.2976 - val_accuracy: 0.8761\u001b[0m - loss: 0.7449 - accuracy: 0.50\n",
      "\u001b[35m2022-09-09 19:17:54.247 \u001b[0m\u001b[32m[1662769070414351/train/3 (pid 42554)] \u001b[0m\u001b[22mEpoch 2/10\u001b[0m\n",
      "510/510 [==============================] - 0s 638us/step - loss: 0.2953 - accuracy: 0.8807 - val_loss: 0.2999 - val_accuracy: 0.8744\u001b[0m loss: 0.2596 - accuracy: 0.90\n",
      "\u001b[35m2022-09-09 19:17:54.573 \u001b[0m\u001b[32m[1662769070414351/train/3 (pid 42554)] \u001b[0m\u001b[22mEpoch 3/10\u001b[0m\n",
      "510/510 [==============================] - 0s 711us/step - loss: 0.2845 - accuracy: 0.8855 - val_loss: 0.2959 - val_accuracy: 0.8781\u001b[0m loss: 0.1996 - accuracy: 0.93\n",
      "\u001b[35m2022-09-09 19:17:54.936 \u001b[0m\u001b[32m[1662769070414351/train/3 (pid 42554)] \u001b[0m\u001b[22mEpoch 4/10\u001b[0m\n",
      "510/510 [==============================] - 0s 667us/step - loss: 0.2764 - accuracy: 0.8896 - val_loss: 0.2987 - val_accuracy: 0.8707\u001b[0m loss: 0.4235 - accuracy: 0.84\n",
      "\u001b[35m2022-09-09 19:17:55.276 \u001b[0m\u001b[32m[1662769070414351/train/3 (pid 42554)] \u001b[0m\u001b[22mEpoch 5/10\u001b[0m\n",
      "510/510 [==============================] - 0s 644us/step - loss: 0.2648 - accuracy: 0.8963 - val_loss: 0.3031 - val_accuracy: 0.8746\u001b[0m loss: 0.1530 - accuracy: 0.96\n",
      "\u001b[35m2022-09-09 19:17:55.605 \u001b[0m\u001b[32m[1662769070414351/train/3 (pid 42554)] \u001b[0m\u001b[22mEpoch 6/10\u001b[0m\n",
      "510/510 [==============================] - 0s 626us/step - loss: 0.2579 - accuracy: 0.9018 - val_loss: 0.3049 - val_accuracy: 0.8786\u001b[0m loss: 0.2367 - accuracy: 0.93\n",
      "\u001b[35m2022-09-09 19:17:55.925 \u001b[0m\u001b[32m[1662769070414351/train/3 (pid 42554)] \u001b[0m\u001b[22mEpoch 7/10\u001b[0m\n",
      "510/510 [==============================] - 0s 641us/step - loss: 0.2499 - accuracy: 0.9077 - val_loss: 0.3082 - val_accuracy: 0.8714\u001b[0m loss: 0.4736 - accuracy: 0.81\n",
      "\u001b[35m2022-09-09 19:17:56.252 \u001b[0m\u001b[32m[1662769070414351/train/3 (pid 42554)] \u001b[0m\u001b[22mEpoch 8/10\u001b[0m\n",
      "510/510 [==============================] - 0s 632us/step - loss: 0.2422 - accuracy: 0.9097 - val_loss: 0.3268 - val_accuracy: 0.8741\u001b[0m loss: 0.2049 - accuracy: 0.96\n",
      "\u001b[35m2022-09-09 19:17:56.574 \u001b[0m\u001b[32m[1662769070414351/train/3 (pid 42554)] \u001b[0m\u001b[22mEpoch 9/10\u001b[0m\n",
      "510/510 [==============================] - 0s 628us/step - loss: 0.2327 - accuracy: 0.9161 - val_loss: 0.3175 - val_accuracy: 0.8751\u001b[0m loss: 0.3183 - accuracy: 0.81\n",
      "\u001b[35m2022-09-09 19:17:56.895 \u001b[0m\u001b[32m[1662769070414351/train/3 (pid 42554)] \u001b[0m\u001b[22mEpoch 10/10\u001b[0m\n",
      "510/510 [==============================] - 0s 652us/step - loss: 0.2227 - accuracy: 0.9223 - val_loss: 0.3373 - val_accuracy: 0.8690\u001b[0m loss: 0.1643 - accuracy: 0.90\n",
      "\u001b[35m2022-09-09 19:17:57.376 \u001b[0m\u001b[32m[1662769070414351/train/3 (pid 42554)] \u001b[0m\u001b[22m2022-09-09 19:17:57.376435: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[35m2022-09-09 19:17:57.377 \u001b[0m\u001b[32m[1662769070414351/train/3 (pid 42554)] \u001b[0m\u001b[22mWARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\u001b[0m\n",
      "\u001b[35m2022-09-09 19:17:57.828 \u001b[0m\u001b[32m[1662769070414351/train/3 (pid 42554)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-09-09 19:17:57.833 \u001b[0m\u001b[32m[1662769070414351/join/4 (pid 42559)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-09-09 19:17:59.619 \u001b[0m\u001b[32m[1662769070414351/join/4 (pid 42559)] \u001b[0m\u001b[22m2022-09-09 19:17:59.618810: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\u001b[0m\n",
      "\u001b[35m2022-09-09 19:17:59.743 \u001b[0m\u001b[32m[1662769070414351/join/4 (pid 42559)] \u001b[0m\u001b[22mBaseline Acccuracy: 77.30%\u001b[0m\n",
      "\u001b[35m2022-09-09 19:17:59.888 \u001b[0m\u001b[32m[1662769070414351/join/4 (pid 42559)] \u001b[0m\u001b[22m2022-09-09 19:17:59.888310: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[35m2022-09-09 19:17:59.890 \u001b[0m\u001b[32m[1662769070414351/join/4 (pid 42559)] \u001b[0m\u001b[22mWARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\u001b[0m\n",
      "\u001b[35m2022-09-09 19:18:00.318 \u001b[0m\u001b[32m[1662769070414351/join/4 (pid 42559)] \u001b[0m\u001b[22mBaseline AUC: 0.5\u001b[0m\n",
      "\u001b[35m2022-09-09 19:18:00.318 \u001b[0m\u001b[32m[1662769070414351/join/4 (pid 42559)] \u001b[0m\u001b[22mModel Acccuracy: 86.97%\u001b[0m\n",
      "\u001b[35m2022-09-09 19:18:00.318 \u001b[0m\u001b[32m[1662769070414351/join/4 (pid 42559)] \u001b[0m\u001b[22mModel AUC: 0.91\u001b[0m\n",
      "\u001b[35m2022-09-09 19:18:00.319 \u001b[0m\u001b[32m[1662769070414351/join/4 (pid 42559)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-09-09 19:18:00.324 \u001b[0m\u001b[32m[1662769070414351/end/5 (pid 42562)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-09-09 19:18:01.766 \u001b[0m\u001b[32m[1662769070414351/end/5 (pid 42562)] \u001b[0m\u001b[22mModel beats baseline (T/F): True\u001b[0m\n",
      "\u001b[35m2022-09-09 19:18:01.775 \u001b[0m\u001b[32m[1662769070414351/end/5 (pid 42562)] \u001b[0m\u001b[22m2022-09-09 19:18:01.775348: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\u001b[0m\n",
      "\u001b[35m2022-09-09 19:18:01.805 \u001b[0m\u001b[32m[1662769070414351/end/5 (pid 42562)] \u001b[0m\u001b[22mModel passed smoke test (T/F): True\u001b[0m\n",
      "\u001b[35m2022-09-09 19:18:01.946 \u001b[0m\u001b[32m[1662769070414351/end/5 (pid 42562)] \u001b[0m\u001b[22m2022-09-09 19:18:01.946293: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[35m2022-09-09 19:18:01.948 \u001b[0m\u001b[32m[1662769070414351/end/5 (pid 42562)] \u001b[0m\u001b[22mWARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\u001b[0m\n",
      "\u001b[35m2022-09-09 19:18:02.357 \u001b[0m\u001b[32m[1662769070414351/end/5 (pid 42562)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-09-09 19:18:02.357 \u001b[0m\u001b[1mDone!\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#notest\n",
    "! python nlpflow.py run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9997bb4-995c-4b5b-8f11-cd396dd49dbe",
   "metadata": {},
   "source": [
    "Now that we have tagged our model if it meets our minimum standards, we are now ready to use this model in downstream workflows.  In the next lesson, we will explore different ways you can utilize the model you have trained."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
