{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22395431-e23d-422a-9e85-5d617f66fc82",
   "metadata": {},
   "source": [
    "#### What You Will Learn\n",
    "At the end of this lesson you will:\n",
    "    \n",
    "* Learn how to build a simple NLP model using Tensorflow and scikit-learn to classify fashion reviews\n",
    "* Learn how to setup your model so that it can be easily used in Metaflow\n",
    "\n",
    "#### Background\n",
    "\n",
    "We are going to build a model that does classifies customer reviews as positive or negative sentiment, using the [Women's E-Commerce Clothing Reviews Dataset](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews). Here is what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6657028f-ceab-434b-b53d-453c82dced6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of rows: 20377\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('train.parquet')\n",
    "print(f'num of rows: {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dccde6e-d538-4f3d-b65e-f6db7d623672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Odd fit: I wanted to love this sweater but the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Very comfy dress: The quality and material of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Fits nicely but fabric a bit thin: I ordered t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Great fit: Love these jeans, fit and style... ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Stretches out, washes poorly. wish i could ret...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                             review\n",
       "0       0  Odd fit: I wanted to love this sweater but the...\n",
       "1       1  Very comfy dress: The quality and material of ...\n",
       "2       0  Fits nicely but fabric a bit thin: I ordered t...\n",
       "3       1  Great fit: Love these jeans, fit and style... ...\n",
       "4       0  Stretches out, washes poorly. wish i could ret..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc98ba7b-aa75-4960-90b0-3ad6b8481a43",
   "metadata": {},
   "source": [
    "Before we begin training a model, it is useful to set a baseline.  One such baseline is the majority-class classifier, which measures what happens when we label all of our examples with the majority class.  We can then calculate our performance metrics by using this baseline model, which in this case is [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) and the [area under the ROC curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541604f9-6882-4424-92f1-409d3f281e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.773\n",
      "Baseline AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "valdf = pd.read_parquet('valid.parquet')\n",
    "baseline_predictions = [1] * valdf.shape[0]\n",
    "base_acc = accuracy_score(valdf.labels, baseline_predictions)\n",
    "base_rocauc = roc_auc_score(valdf.labels, baseline_predictions)\n",
    "\n",
    "print(f'Baseline Accuracy: {base_acc:.3f}\\nBaseline AUC: {base_rocauc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298d9a86-f982-4ad2-bc25-73171b5ac3c0",
   "metadata": {},
   "source": [
    "Now its time to build our ML model.  We are going to define our model in a seperate file with a custom class called `Nbow_Model`.  The model contains two subcomponents: the count vectorizer for preprocessing and the model.  This class facilitates combining these two components together so that we don't have to deal with them seperately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b13fce-f64f-45db-a43d-4098540c084f",
   "metadata": {},
   "source": [
    "Next, let's import the `NbowModel` and train it on this dataset.  The purpose of doing this is to make sure the code works as we expect before using Metaflow.  For this example, we will set our `vocab_sz = 750`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad60de67-222b-4c28-8ec1-502845f17163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.3619 - accuracy: 0.8447 - val_loss: 0.3018 - val_accuracy: 0.8707\n",
      "Epoch 2/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2945 - accuracy: 0.8797 - val_loss: 0.2923 - val_accuracy: 0.8776\n",
      "Epoch 3/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2837 - accuracy: 0.8855 - val_loss: 0.2949 - val_accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2708 - accuracy: 0.8925 - val_loss: 0.3075 - val_accuracy: 0.8744\n",
      "Epoch 5/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2623 - accuracy: 0.8982 - val_loss: 0.3036 - val_accuracy: 0.8795\n",
      "Epoch 6/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2530 - accuracy: 0.9043 - val_loss: 0.3052 - val_accuracy: 0.8756\n",
      "Epoch 7/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2441 - accuracy: 0.9104 - val_loss: 0.3104 - val_accuracy: 0.8766\n",
      "Epoch 8/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2356 - accuracy: 0.9158 - val_loss: 0.3193 - val_accuracy: 0.8744\n",
      "Epoch 9/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2254 - accuracy: 0.9203 - val_loss: 0.3316 - val_accuracy: 0.8697\n",
      "Epoch 10/10\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2145 - accuracy: 0.9261 - val_loss: 0.3330 - val_accuracy: 0.8734\n"
     ]
    }
   ],
   "source": [
    "#notest\n",
    "from model import NbowModel\n",
    "model = NbowModel(vocab_sz=750)\n",
    "model.fit(X=df['review'], y=df['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da3c613-4238-4818-92c7-5c531f4e5f6a",
   "metadata": {},
   "source": [
    "Next, we can evaluate our model on the validation set as well, using the built in evaluation methods we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417907e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_acc = model.eval_acc(valdf['review'], valdf['labels'])\n",
    "model_rocauc = model.eval_rocauc(valdf['review'], valdf['labels'])\n",
    "\n",
    "print(f'Baseline Accuracy: {model_acc:.3f}\\nBaseline AUC: {model_rocauc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b757370c-a330-4397-a09c-31b485a24185",
   "metadata": {},
   "source": [
    "Great! This is an improvement upon our baseline!  Now we have setup what we need to start using Metaflow.  In the next lesson, we are going to operationalize the steps we manually performed here into a Flow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "42fd40e048e0585f88ec242f050f7ef0895cf845a8dd1159352394e5826cd102"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
