{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d8c49a7a-e52b-42c7-bdaf-7d7db37e0b12",
   "metadata": {},
   "source": [
    "---\n",
    "title: Episode 1\n",
    "slug: /docs/nlp-tutorial-L1\n",
    "tags: [orchestration]\n",
    "sidebar_label: Episode 1\n",
    "id: nlp-tutorial-L1\n",
    "description: A tutorial that uses Keras, Scikit-Learn, and Metaflow to operationalize a machine learning workflow.\n",
    "category: tutorials\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d65b4d-372a-42ce-b7ec-344ed8ff1072",
   "metadata": {},
   "source": [
    "### Setup Instructions\n",
    "\n",
    "If you haven't done so, please follow the [setup instructions](./nlp-tutorial-setup) to prepare your environment.  This tutorial will be referencing this [Notebook](https://github.com/outerbounds/tutorials/blob/main/nlp/nlp-1.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22395431-e23d-422a-9e85-5d617f66fc82",
   "metadata": {},
   "source": [
    "#### What You Will Learn\n",
    "\n",
    "At the end of this lesson you will become familiar with the dataset and the baseline relevant to the business problem we want to solve.\n",
    "\n",
    "#### Background\n",
    "\n",
    "We are going to build a model that does classifies customer reviews as positive or negative sentiment, using the [Women's E-Commerce Clothing Reviews Dataset](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews). Here is what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6657028f-ceab-434b-b53d-453c82dced6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of rows: 20377\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('train.parquet')\n",
    "print(f'num of rows: {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a06d7a-c64a-492d-97cc-fa3396581ec4",
   "metadata": {},
   "source": [
    "The data is stored in a [parquet file](https://parquet.apache.org/), which is a framework agnostic way of storing data that you are likely to encounter in the wild.  It works seamlessly with pandas, and is a format that is commonly available if your data is already in a database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dccde6e-d538-4f3d-b65e-f6db7d623672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Odd fit: I wanted to love this sweater but the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Very comfy dress: The quality and material of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Fits nicely but fabric a bit thin: I ordered t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Great fit: Love these jeans, fit and style... ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Stretches out, washes poorly. wish i could ret...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                             review\n",
       "0       0  Odd fit: I wanted to love this sweater but the...\n",
       "1       1  Very comfy dress: The quality and material of ...\n",
       "2       0  Fits nicely but fabric a bit thin: I ordered t...\n",
       "3       1  Great fit: Love these jeans, fit and style... ...\n",
       "4       0  Stretches out, washes poorly. wish i could ret..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc98ba7b-aa75-4960-90b0-3ad6b8481a43",
   "metadata": {},
   "source": [
    "Before we begin training a model, it is useful to set a baseline.  One such baseline is the majority-class classifier, which measures what happens when we label all of our examples with the majority class.  We can then calculate our performance metrics by using this baseline model, which in this case is [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) and the [area under the ROC curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541604f9-6882-4424-92f1-409d3f281e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.773\n",
      "Baseline AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "valdf = pd.read_parquet('valid.parquet')\n",
    "baseline_predictions = [1] * valdf.shape[0]\n",
    "base_acc = accuracy_score(valdf.labels, baseline_predictions)\n",
    "base_rocauc = roc_auc_score(valdf.labels, baseline_predictions)\n",
    "\n",
    "print(f'Baseline Accuracy: {base_acc:.3f}\\nBaseline AUC: {base_rocauc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104dbca5-f3a7-483e-ba64-e30914a03748",
   "metadata": {},
   "source": [
    "Now that we understand the dataset and the problem a bit more, we can now start building our model.  We will draw upon machine learning techniques from [natural language processing](https://en.wikipedia.org/wiki/Natural_language_processing) to see if we can train an algorithm to predict the sentiment of these fashion reviews."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
