{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d8c49a7a-e52b-42c7-bdaf-7d7db37e0b12",
   "metadata": {},
   "source": [
    "---\n",
    "title: Episode 6\n",
    "slug: /docs/nlp-tutorial-L6\n",
    "tags: [orchestration]\n",
    "sidebar_label: Episode 6\n",
    "id: nlp-tutorial-L6\n",
    "description: A tutorial that uses Keras, Scikit-Learn, and Metaflow to operationalize a machine learning workflow.\n",
    "category: tutorials\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cda407-18aa-4a1b-9a04-03d6416b4b8e",
   "metadata": {},
   "source": [
    "### Setup Instructions\n",
    "\n",
    "If you haven't done so, please follow the [setup instructions](./nlp-tutorial-setup) to prepare your environment.  This tutorial will be referencing two pieces of code:\n",
    "\n",
    "\n",
    "1.  [Notebook](https://github.com/outerbounds/tutorials/blob/main/nlp/nlp-5.ipynb) for this lesson.\n",
    "2.  [predflow.py](https://github.com/outerbounds/tutorials/blob/main/nlp/predflow.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df04b2b-eab2-49ac-a591-9b43f39a4aaa",
   "metadata": {},
   "source": [
    "#### What You Will Learn\n",
    "At the end of this lesson, you will:\n",
    "    \n",
    "* Learn how to retrieve your model for use in downstream systems with the client API.\n",
    "* Learn how you retrieve your model in a separate flow for predictions.\n",
    "\n",
    "In Episode 5, you saw how we trained a model and tagged the model if it passed certain tests to indicate that it was ready for downstream processes.  In this lesson, we show you how you can retrieve this model in other Flows, but also outside of flows with the client API."
   ]
  },
  {
   "cell_type": "raw",
   "id": "67acad84-46fb-4f73-b6d0-73eb19bc73f5",
   "metadata": {},
   "source": [
    "### <NumberHeading number={1}>Using The Client API</NumberHeading>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359b29d2-e7d3-472f-93b3-3e9d56ff6909",
   "metadata": {},
   "source": [
    "In addition to manipulating tags as seen the previous lesson, the Metaflow [client API](https://docs.metaflow.org/api/client) allows you to access data from past runs.  For example, this is how you can retrieve a model tagged as a `deployment candidate` outside Metaflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86877e4c-3cf2-4501-8875-0090388f998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import Flow\n",
    "\n",
    "def get_latest_successful_run(flow_nm, tag):\n",
    "    \"Gets the latest successfull run for a flow with a specific tag.\"\n",
    "    for r in Flow(flow_nm).runs(tag):\n",
    "        if r.successful: return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc88697-0295-4ec8-8e5f-66883449ee6f",
   "metadata": {},
   "source": [
    "The above code allows you to retrieve runs for flows matching `flow_nm` and filter them according to whether or not they are tagged with `tag`. Finally, we check if the run is successfull with the `successful` property. \n",
    "\n",
    "After retrieving the model's data with the client API, we can load the model like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9186d3-c876-4641-b74f-7ecb36469550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_output\n",
    "#notest\n",
    "from model import NbowModel\n",
    "\n",
    "run = get_latest_successful_run('NLPFlow', 'deployment_candidate')\n",
    "model = NbowModel.from_dict(run.data.model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f27cf16-5959-4def-9b0a-51f46f8c39c3",
   "metadata": {},
   "source": [
    "Now that we have retrieved the model using the tag we can use it to make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d53d9-9186-42ea-bf91-6ac460322b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99930894],\n",
       "       [0.9928788 ],\n",
       "       [0.99954474],\n",
       "       ...,\n",
       "       [0.9996772 ],\n",
       "       [0.9996848 ],\n",
       "       [0.23608246]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#notest\n",
    "import pandas as pd\n",
    "\n",
    "predict_df = pd.read_parquet('predict.parquet')\n",
    "preds = model.predict(predict_df['review'])\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1533abf-5723-4563-9ea8-add4b5beedc5",
   "metadata": {},
   "source": [
    "You can write these predictions to a parquet file like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90fd83-c601-43c9-80f4-3d0414629506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "pa_tbl = pa.table({\"data\": preds.squeeze()})\n",
    "pa.parquet.write_table(pa_tbl, \"sentiment_predictions.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1753c3b6-5c5a-4b08-84c0-86619eb61094",
   "metadata": {},
   "source": [
    "With the client API, you can retrieve your artifacts in whatever downstream application you want, or even just use the API for ad-hoc testing."
   ]
  },
  {
   "cell_type": "raw",
   "id": "678243b6-72ad-45b5-90df-788af715180c",
   "metadata": {},
   "source": [
    "<Wrapper>\n",
    "\n",
    "### <NumberHeading number={2}>Retrieving Prediction In A Flow</NumberHeading>\n",
    "\n",
    "<Highlight>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1759df-3122-4ac6-b23c-8ae07a8386b6",
   "metadata": {},
   "source": [
    "We can utilize the client api to also retrieve model artifacts within a flow!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e214fe37-7b83-40e7-9229-d6ae33723a21",
   "metadata": {},
   "source": [
    "</Highlight>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f9c8bd-2a6e-41da-99cd-563dfe53f3e2",
   "metadata": {},
   "source": [
    " In this flow, we will perform the following steps:\n",
    "\n",
    "1. Get the latest deployment candidate using the Metaflow API in the `start` step.  Recall that the name of our previous flow is `NLPFlow`.\n",
    "2. Make predictions with our deployment candidate on a new dataset and write that to a parquet file in the `end` step"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88cf1b61-05fd-411c-bc5d-bdad76f77c2b",
   "metadata": {},
   "source": [
    "<RHS>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d963d32-b173-40fa-abdd-716dbed09319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predflow.py\n",
    "\n",
    "from metaflow import FlowSpec, step, Flow, current\n",
    "\n",
    "class NLPredictionFlow(FlowSpec):\n",
    "    \n",
    "    def get_latest_successful_run(self, flow_nm, tag):\n",
    "        \"Gets the latest successfull run for a flow with a specific tag.\"\n",
    "        for r in Flow(flow_nm).runs(tag):\n",
    "            if r.successful: return r\n",
    "        \n",
    "    @step\n",
    "    def start(self):\n",
    "        \"Get the latest deployment candidate that is from a successfull run\"\n",
    "        self.deploy_run = self.get_latest_successful_run('NLPFlow', 'deployment_candidate')\n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        \"Make predictions\"\n",
    "        from model import NbowModel\n",
    "        import pandas as pd\n",
    "        import pyarrow as pa\n",
    "        new_reviews = pd.read_parquet('predict.parquet')['review']\n",
    "        \n",
    "        # Make predictions\n",
    "        model = NbowModel.from_dict(self.deploy_run.data.model_dict)\n",
    "        predictions = model.predict(new_reviews)\n",
    "        print(f'Writing predictions to parquet: {predictions.shape[0]:,} rows')\n",
    "        pa_tbl = pa.table({\"data\": predictions.squeeze()})\n",
    "        pa.parquet.write_table(pa_tbl, \"sentiment_predictions.parquet\")\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    NLPredictionFlow()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57f0e1a2-6931-44ac-b0fe-b8211b55393e",
   "metadata": {},
   "source": [
    "</RHS>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3728a897-9ecd-4e2b-b58f-492b25f02b7c",
   "metadata": {},
   "source": [
    "### <NumberHeading number={3}>Run Flow</NumberHeading>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126fad4-3299-4b4d-946e-9b3bdf16f1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.7.1\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mNLPredictionFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:hamel\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-08-11 14:52:02.786 \u001b[0m\u001b[1mWorkflow starting (run-id 1660254722779868):\u001b[0m\n",
      "\u001b[35m2022-08-11 14:52:02.794 \u001b[0m\u001b[32m[1660254722779868/start/1 (pid 37189)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-08-11 14:52:03.577 \u001b[0m\u001b[32m[1660254722779868/start/1 (pid 37189)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-08-11 14:52:03.587 \u001b[0m\u001b[32m[1660254722779868/end/2 (pid 37193)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-08-11 14:52:06.101 \u001b[0m\u001b[32m[1660254722779868/end/2 (pid 37193)] \u001b[0m\u001b[22m2022-08-11 14:52:06.101443: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\u001b[0m\n",
      "\u001b[35m2022-08-11 14:52:06.452 \u001b[0m\u001b[32m[1660254722779868/end/2 (pid 37193)] \u001b[0m\u001b[22mWriting predictions to parquet: 2,264 rows\u001b[0m\n",
      "\u001b[35m2022-08-11 14:52:06.742 \u001b[0m\u001b[32m[1660254722779868/end/2 (pid 37193)] \u001b[0m\u001b[22mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2022-08-11 14:52:06.744 \u001b[0m\u001b[32m[1660254722779868/end/2 (pid 37193)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-08-11 14:52:06.744 \u001b[0m\u001b[1mDone!\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#notest\n",
    "! python predflow.py run"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c70273d-fd21-4bd7-b533-41ee299264c4",
   "metadata": {},
   "source": [
    "</Wrapper>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d4d6a-7114-4e29-9e6c-8ada275f09e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f038b7c9-2e17-46c7-b9eb-516209208461",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Congratulations!  You have learned how to:\n",
    "\n",
    "1. Create a baseline flow that reads data and computes a baseline.\n",
    "2. How to use branching to perform steps in parallel.\n",
    "3. Best practices for serializing and de-serializing models in Metaflow.\n",
    "4. How to use tagging to evaluate and gate models for production.\n",
    "5. How to retrieve your model both outside Metaflow and from another flow.\n",
    "\n",
    "### Further Discussion\n",
    "\n",
    "This is a very simple example that will also run on your laptop.  However, for production use cases you may want to use [@conda](https://docs.metaflow.org/metaflow/dependencies#managing-dependencies-with-conda-decorator) for dependency management, [@batch](https://docs.metaflow.org/v/r/metaflow/scaling#using-aws-batch) or [@kubernetes](https://docs.metaflow.org/metaflow/scaling-out-and-up/effortless-scaling-with-kubernetes) for remote execution, and [@schedule](https://docs.metaflow.org/going-to-production-with-metaflow/scheduling-metaflow-flows/scheduling-with-aws-step-functions#scheduling-a-flow) to schedule jobs to run periodically.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2999bb1a-4ec9-4b10-a7cf-904e9f6a279a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
