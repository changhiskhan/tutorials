{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d8c49a7a-e52b-42c7-bdaf-7d7db37e0b12",
   "metadata": {},
   "source": [
    "---\n",
    "title: Text Classification With Keras and Scikit-Learn\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae728d37-c9c0-4504-b081-ababbf7a1c25",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Background\n",
    "\n",
    "We are going to build a model that does classifies customer reviews as positive or negative sentiment, using the [Women's E-Commerce Clothing Reviews Dataset](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews).  We will walk you through how we would organize this task in Metaflow.  Concretely, we will demonstrate the following steps:\n",
    "\n",
    "1. Read data from a parquet file\n",
    "2. Show a branching workflow to record a baseline and train a model in parallel.  \n",
    "3. Evaluate The Model:\n",
    "    - on a holdout set and compare against the baseline\n",
    "    - do a smaoke test\n",
    "4. Retrain the model on the whole dataset if it passsed the criteria and tag it accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e372da2-95d6-4be3-a47e-c676ba7ee18f",
   "metadata": {},
   "source": [
    "## Constructing The Metaflow Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "75e3b107-901e-46b2-8db0-90846edd261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile flow.py\n",
    "\n",
    "from metaflow import FlowSpec, step, Flow, current\n",
    "\n",
    "class MyFlow(FlowSpec):\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "        \"Read the data\"\n",
    "        import pandas as pd\n",
    "        self.df = pd.read_parquet('train.parquet')\n",
    "        print(f'num of rows: {self.df.shape[0]}')\n",
    "        self.next(self.baseline, self.train)\n",
    "\n",
    "    @step\n",
    "    def baseline(self):\n",
    "        \"Compute the baseline\"\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "        baseline_predictions = [1] * self.df.shape[0]\n",
    "        self.base_acc = accuracy_score(self.df.labels, baseline_predictions)\n",
    "        self.base_rocauc = roc_auc_score(self.df.labels, baseline_predictions)\n",
    "        self.next(self.join)\n",
    "\n",
    "    @step\n",
    "    def train(self):\n",
    "        \"Train the model\"\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.keras.utils import set_random_seed\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        from model import get_model\n",
    "        set_random_seed(2022)\n",
    "        \n",
    "        self.cv = CountVectorizer(min_df=.005, max_df = .75, stop_words='english', strip_accents='ascii', )\n",
    "        res = self.cv.fit_transform(self.df['review'])\n",
    "        self.model = get_model(len(self.cv.vocabulary_))\n",
    "        self.model.fit(x=res.toarray(), \n",
    "                       y=self.df['labels'],\n",
    "                       batch_size=32, epochs=10, validation_split=.2)\n",
    "\n",
    "        self.next(self.join)\n",
    "        \n",
    "    @step\n",
    "    def join(self, inputs):\n",
    "        \"Compare the model results with the baseline.\"\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.keras import layers, optimizers, regularizers\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        import pandas as pd\n",
    "        \n",
    "        \n",
    "        self.model = inputs.train.model\n",
    "        self.cv = inputs.train.cv\n",
    "        self.train_df = inputs.train.df\n",
    "        self.holdout_df = pd.read_parquet('holdout.parquet')\n",
    "        \n",
    "        self.predictions = self.model.predict(self.cv.transform(self.holdout_df['review']).toarray())\n",
    "        labels = self.holdout_df['labels']\n",
    "        \n",
    "        self.model_acc = accuracy_score(labels, self.predictions > .5)\n",
    "        self.model_rocauc = roc_auc_score(labels, self.predictions)\n",
    "        \n",
    "        print(f'Baseline Acccuracy: {inputs.baseline.base_acc:.2%}')\n",
    "        print(f'Baseline AUC: {inputs.baseline.base_rocauc:.2}')\n",
    "        print(f'Model Acccuracy: {self.model_acc:.2%}')\n",
    "        print(f'Model AUC: {self.model_rocauc:.2}')\n",
    "        self.beats_baseline = self.model_rocauc > inputs.baseline.base_rocauc\n",
    "        print(f'Model beats baseline (T/F): {self.beats_baseline}')\n",
    "        \n",
    "        #smoke test to make sure model is doing the right thing on obvious examples.\n",
    "        _tst_reviews = [\"poor fit its baggy in places where it isn't supposed to be.\",\n",
    "                        \"love it, very high quality and great value\"]\n",
    "        _tst_preds = self.model.predict(self.cv.transform(_tst_reviews).toarray())\n",
    "        self.passed_smoke_test = _tst_preds[0][0] < .5 and _tst_preds[1][0] > .5\n",
    "        print(f'Model passed smoke test (T/F): {self.passed_smoke_test}')\n",
    "        \n",
    "        self.next(self.retrain)\n",
    "\n",
    "    @step\n",
    "    def retrain(self):\n",
    "        \"If model beats the baseline and passes smoke tests, then retrain the model on all available data.\"\n",
    "        if self.beats_baseline and self.passed_smoke_test:\n",
    "            from sklearn.feature_extraction.text import CountVectorizer\n",
    "            from tensorflow.keras.utils import set_random_seed\n",
    "            import pandas as pd\n",
    "            from model import get_model\n",
    "            \n",
    "            set_random_seed(2022)\n",
    "            all_df = pd.concat([self.train_df, self.holdout_df])\n",
    "            res = self.cv.transform(all_df['review'])\n",
    "            self.final_model = get_model(len(self.cv.vocabulary_))\n",
    "\n",
    "            self.final_model.fit(x=res.toarray(), \n",
    "                                 y=all_df['labels'],\n",
    "                                 batch_size=32, epochs=10, validation_split=.1)\n",
    "            run = Flow(current.flow_name)[current.run_id]\n",
    "            run.add_tag('deployment_candidate')\n",
    "        else:\n",
    "            print('Model was not retrained on full data because of failed smoke test or performance below the baseline.')\n",
    "        self.next(self.end)\n",
    "        \n",
    "    @step\n",
    "    def end(self): ...\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MyFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd4d84c0-f9a0-4d30-b2e9-464178830548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.7.1\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mMyFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:hamel\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:36.258 \u001b[0m\u001b[1mWorkflow starting (run-id 1658273436252649):\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:36.268 \u001b[0m\u001b[32m[1658273436252649/start/1 (pid 26072)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:37.244 \u001b[0m\u001b[32m[1658273436252649/start/1 (pid 26072)] \u001b[0m\u001b[22mnum of rows: 20377\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:37.362 \u001b[0m\u001b[32m[1658273436252649/start/1 (pid 26072)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:37.371 \u001b[0m\u001b[32m[1658273436252649/baseline/2 (pid 26076)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:37.380 \u001b[0m\u001b[32m[1658273436252649/train/3 (pid 26077)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:38.766 \u001b[0m\u001b[32m[1658273436252649/baseline/2 (pid 26076)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:40.535 \u001b[0m\u001b[32m[1658273436252649/train/3 (pid 26077)] \u001b[0m\u001b[22m2022-07-19 16:30:40.535577: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:40.618 \u001b[0m\u001b[32m[1658273436252649/train/3 (pid 26077)] \u001b[0m\u001b[22mEpoch 1/10\u001b[0m\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.3523 - accuracy: 0.8507 - val_loss: 0.2988 - val_accuracy: 0.8754\u001b[0m52 - loss: 0.6811 - accuracy: 0.6\n",
      "\u001b[35m2022-07-19 16:30:41.500 \u001b[0m\u001b[32m[1658273436252649/train/3 (pid 26077)] \u001b[0m\u001b[22mEpoch 2/10\u001b[0m\n",
      "510/510 [==============================] - 1s 994us/step - loss: 0.2945 - accuracy: 0.8818 - val_loss: 0.2956 - val_accuracy: 0.8771\u001b[0m loss: 0.2944 - accuracy: 0.90\n",
      "\u001b[35m2022-07-19 16:30:42.008 \u001b[0m\u001b[32m[1658273436252649/train/3 (pid 26077)] \u001b[0m\u001b[22mEpoch 3/10\u001b[0m\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2860 - accuracy: 0.8840 - val_loss: 0.2989 - val_accuracy: 0.8768\u001b[0m - loss: 0.2319 - accuracy: 0.96\n",
      "\u001b[35m2022-07-19 16:30:42.528 \u001b[0m\u001b[32m[1658273436252649/train/3 (pid 26077)] \u001b[0m\u001b[22mEpoch 4/10\u001b[0m\n",
      "510/510 [==============================] - 0s 978us/step - loss: 0.2761 - accuracy: 0.8891 - val_loss: 0.2951 - val_accuracy: 0.8803\u001b[0m loss: 0.3847 - accuracy: 0.81\n",
      "\u001b[35m2022-07-19 16:30:43.027 \u001b[0m\u001b[32m[1658273436252649/train/3 (pid 26077)] \u001b[0m\u001b[22mEpoch 5/10\u001b[0m\n",
      "510/510 [==============================] - 0s 950us/step - loss: 0.2676 - accuracy: 0.8956 - val_loss: 0.2991 - val_accuracy: 0.8759\u001b[0m loss: 0.2714 - accuracy: 0.93\n",
      "\u001b[35m2022-07-19 16:30:43.512 \u001b[0m\u001b[32m[1658273436252649/train/3 (pid 26077)] \u001b[0m\u001b[22mEpoch 6/10\u001b[0m\n",
      "510/510 [==============================] - 0s 948us/step - loss: 0.2623 - accuracy: 0.9005 - val_loss: 0.2996 - val_accuracy: 0.8793\u001b[0m loss: 0.3324 - accuracy: 0.84\n",
      "\u001b[35m2022-07-19 16:30:43.996 \u001b[0m\u001b[32m[1658273436252649/train/3 (pid 26077)] \u001b[0m\u001b[22mEpoch 7/10\u001b[0m\n",
      "510/510 [==============================] - 0s 950us/step - loss: 0.2549 - accuracy: 0.9056 - val_loss: 0.3044 - val_accuracy: 0.8754\u001b[0m loss: 0.2044 - accuracy: 0.93\n",
      "\u001b[35m2022-07-19 16:30:44.482 \u001b[0m\u001b[32m[1658273436252649/train/3 (pid 26077)] \u001b[0m\u001b[22mEpoch 8/10\u001b[0m\n",
      "510/510 [==============================] - 0s 952us/step - loss: 0.2472 - accuracy: 0.9109 - val_loss: 0.3137 - val_accuracy: 0.8759\u001b[0m loss: 0.2832 - accuracy: 0.84\n",
      "\u001b[35m2022-07-19 16:30:44.968 \u001b[0m\u001b[32m[1658273436252649/train/3 (pid 26077)] \u001b[0m\u001b[22mEpoch 9/10\u001b[0m\n",
      "510/510 [==============================] - 0s 950us/step - loss: 0.2376 - accuracy: 0.9134 - val_loss: 0.3151 - val_accuracy: 0.8776\u001b[0m loss: 0.2699 - accuracy: 0.93\n",
      "\u001b[35m2022-07-19 16:30:45.452 \u001b[0m\u001b[32m[1658273436252649/train/3 (pid 26077)] \u001b[0m\u001b[22mEpoch 10/10\u001b[0m\n",
      "510/510 [==============================] - 0s 952us/step - loss: 0.2298 - accuracy: 0.9187 - val_loss: 0.3276 - val_accuracy: 0.8744\u001b[0m loss: 0.1719 - accuracy: 0.93\n",
      "\u001b[35m2022-07-19 16:30:46.064 \u001b[0m\u001b[32m[1658273436252649/train/3 (pid 26077)] \u001b[0m\u001b[22mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:46.064 \u001b[0m\u001b[32m[1658273436252649/train/3 (pid 26077)] \u001b[0m\u001b[22m2022-07-19 16:30:46.063950: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:46.091 \u001b[0m\u001b[32m[1658273436252649/train/3 (pid 26077)] \u001b[0m\u001b[22mWARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:46.572 \u001b[0m\u001b[32m[1658273436252649/train/3 (pid 26077)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:46.581 \u001b[0m\u001b[32m[1658273436252649/join/4 (pid 26086)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:49.183 \u001b[0m\u001b[32m[1658273436252649/join/4 (pid 26086)] \u001b[0m\u001b[22m2022-07-19 16:30:49.183104: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:49.623 \u001b[0m\u001b[32m[1658273436252649/join/4 (pid 26086)] \u001b[0m\u001b[22mBaseline Acccuracy: 77.04%\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:49.623 \u001b[0m\u001b[32m[1658273436252649/join/4 (pid 26086)] \u001b[0m\u001b[22mBaseline AUC: 0.5\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:49.646 \u001b[0m\u001b[32m[1658273436252649/join/4 (pid 26086)] \u001b[0m\u001b[22mModel Acccuracy: 87.77%\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:49.646 \u001b[0m\u001b[32m[1658273436252649/join/4 (pid 26086)] \u001b[0m\u001b[22mModel AUC: 0.91\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:49.647 \u001b[0m\u001b[32m[1658273436252649/join/4 (pid 26086)] \u001b[0m\u001b[22mModel beats baseline (T/F): True\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:49.647 \u001b[0m\u001b[32m[1658273436252649/join/4 (pid 26086)] \u001b[0m\u001b[22mModel passed smoke test (T/F): True\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:49.795 \u001b[0m\u001b[32m[1658273436252649/join/4 (pid 26086)] \u001b[0m\u001b[22mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:49.795 \u001b[0m\u001b[32m[1658273436252649/join/4 (pid 26086)] \u001b[0m\u001b[22m2022-07-19 16:30:49.795162: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:49.827 \u001b[0m\u001b[32m[1658273436252649/join/4 (pid 26086)] \u001b[0m\u001b[22mWARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:50.334 \u001b[0m\u001b[32m[1658273436252649/join/4 (pid 26086)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:50.343 \u001b[0m\u001b[32m[1658273436252649/retrain/5 (pid 26090)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:53.664 \u001b[0m\u001b[32m[1658273436252649/retrain/5 (pid 26090)] \u001b[0m\u001b[22m2022-07-19 16:30:53.664709: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\u001b[0m\n",
      "\u001b[35m2022-07-19 16:30:53.752 \u001b[0m\u001b[32m[1658273436252649/retrain/5 (pid 26090)] \u001b[0m\u001b[22mEpoch 1/10\u001b[0m\n",
      "637/637 [==============================] - 1s 1ms/step - loss: 0.3447 - accuracy: 0.8551 - val_loss: 0.3160 - val_accuracy: 0.8724\u001b[0m3:01 - loss: 0.7003 - accuracy: 0.59\n",
      "\u001b[35m2022-07-19 16:30:54.713 \u001b[0m\u001b[32m[1658273436252649/retrain/5 (pid 26090)] \u001b[0m\u001b[22mEpoch 2/10\u001b[0m\n",
      "637/637 [==============================] - 1s 914us/step - loss: 0.2937 - accuracy: 0.8819 - val_loss: 0.3126 - val_accuracy: 0.8720\u001b[0m - loss: 0.2007 - accuracy: 0.93\n",
      "\u001b[35m2022-07-19 16:30:55.296 \u001b[0m\u001b[32m[1658273436252649/retrain/5 (pid 26090)] \u001b[0m\u001b[22mEpoch 3/10\u001b[0m\n",
      "637/637 [==============================] - 1s 925us/step - loss: 0.2865 - accuracy: 0.8854 - val_loss: 0.3107 - val_accuracy: 0.8764\u001b[0m - loss: 0.4833 - accuracy: 0.84\n",
      "\u001b[35m2022-07-19 16:30:55.886 \u001b[0m\u001b[32m[1658273436252649/retrain/5 (pid 26090)] \u001b[0m\u001b[22mEpoch 4/10\u001b[0m\n",
      "637/637 [==============================] - 1s 929us/step - loss: 0.2772 - accuracy: 0.8893 - val_loss: 0.3160 - val_accuracy: 0.8768\u001b[0m - loss: 0.2589 - accuracy: 0.90\n",
      "\u001b[35m2022-07-19 16:30:56.479 \u001b[0m\u001b[32m[1658273436252649/retrain/5 (pid 26090)] \u001b[0m\u001b[22mEpoch 5/10\u001b[0m\n",
      "637/637 [==============================] - 1s 933us/step - loss: 0.2708 - accuracy: 0.8917 - val_loss: 0.3128 - val_accuracy: 0.8759\u001b[0m - loss: 0.3950 - accuracy: 0.84\n",
      "\u001b[35m2022-07-19 16:30:57.073 \u001b[0m\u001b[32m[1658273436252649/retrain/5 (pid 26090)] \u001b[0m\u001b[22mEpoch 6/10\u001b[0m\n",
      "637/637 [==============================] - 1s 917us/step - loss: 0.2631 - accuracy: 0.8978 - val_loss: 0.3152 - val_accuracy: 0.8808\u001b[0m - loss: 0.2537 - accuracy: 0.90\n",
      "\u001b[35m2022-07-19 16:30:57.658 \u001b[0m\u001b[32m[1658273436252649/retrain/5 (pid 26090)] \u001b[0m\u001b[22mEpoch 7/10\u001b[0m\n",
      "637/637 [==============================] - 1s 912us/step - loss: 0.2579 - accuracy: 0.9015 - val_loss: 0.3185 - val_accuracy: 0.8764\u001b[0m - loss: 0.1598 - accuracy: 0.93\n",
      "\u001b[35m2022-07-19 16:30:58.240 \u001b[0m\u001b[32m[1658273436252649/retrain/5 (pid 26090)] \u001b[0m\u001b[22mEpoch 8/10\u001b[0m\n",
      "637/637 [==============================] - 1s 912us/step - loss: 0.2518 - accuracy: 0.9075 - val_loss: 0.3228 - val_accuracy: 0.8786\u001b[0m - loss: 0.1573 - accuracy: 0.96\n",
      "\u001b[35m2022-07-19 16:30:58.821 \u001b[0m\u001b[32m[1658273436252649/retrain/5 (pid 26090)] \u001b[0m\u001b[22mEpoch 9/10\u001b[0m\n",
      "637/637 [==============================] - 1s 907us/step - loss: 0.2442 - accuracy: 0.9110 - val_loss: 0.3325 - val_accuracy: 0.8773\u001b[0m - loss: 0.2313 - accuracy: 0.93\n",
      "\u001b[35m2022-07-19 16:30:59.400 \u001b[0m\u001b[32m[1658273436252649/retrain/5 (pid 26090)] \u001b[0m\u001b[22mEpoch 10/10\u001b[0m\n",
      "637/637 [==============================] - 1s 900us/step - loss: 0.2393 - accuracy: 0.9112 - val_loss: 0.3348 - val_accuracy: 0.8786\u001b[0m - loss: 0.1917 - accuracy: 0.96\n",
      "\u001b[35m2022-07-19 16:31:00.126 \u001b[0m\u001b[32m[1658273436252649/retrain/5 (pid 26090)] \u001b[0m\u001b[22mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:31:00.126 \u001b[0m\u001b[32m[1658273436252649/retrain/5 (pid 26090)] \u001b[0m\u001b[22m2022-07-19 16:31:00.126193: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:31:00.154 \u001b[0m\u001b[32m[1658273436252649/retrain/5 (pid 26090)] \u001b[0m\u001b[22mWARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:31:00.645 \u001b[0m\u001b[32m[1658273436252649/retrain/5 (pid 26090)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:31:00.654 \u001b[0m\u001b[32m[1658273436252649/end/6 (pid 26118)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:31:01.426 \u001b[0m\u001b[32m[1658273436252649/end/6 (pid 26118)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-19 16:31:01.426 \u001b[0m\u001b[1mDone!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python flow.py --no-pylint run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e9894f-a4fb-424b-aa08-f981760ef9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
