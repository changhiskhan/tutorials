{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d8c49a7a-e52b-42c7-bdaf-7d7db37e0b12",
   "metadata": {},
   "source": [
    "---\n",
    "title: Text Classification With Keras and Scikit-Learn\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae728d37-c9c0-4504-b081-ababbf7a1c25",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "We are going to build a model that does classifies customer reviews as positive or negative sentiment, using the [Women's E-Commerce Clothing Reviews Dataset](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews).  We will walk you through how we would organize this task in Metaflow.  Concretely, we will demonstrate the following steps:\n",
    "\n",
    "1. Read data from a parquet file\n",
    "2. Show a branching workflow to record a baseline and train a model in parallel.  \n",
    "3. Evaluate The Model:\n",
    "    - on a holdout set and compare against the baseline\n",
    "    - do a smaoke test\n",
    "4. If the model passes those it is tagged as a `deployment_candidate`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e372da2-95d6-4be3-a47e-c676ba7ee18f",
   "metadata": {},
   "source": [
    "## Constructing The Metaflow Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e3b107-901e-46b2-8db0-90846edd261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile flow.py\n",
    "\n",
    "from metaflow import FlowSpec, step, Flow, current\n",
    "\n",
    "class MyFlow(FlowSpec):\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "        \"Read the data\"\n",
    "        import pandas as pd\n",
    "        self.df = pd.read_parquet('train.parquet')\n",
    "        print(f'num of rows: {self.df.shape[0]}')\n",
    "        self.next(self.baseline, self.train)\n",
    "\n",
    "    @step\n",
    "    def baseline(self):\n",
    "        \"Compute the baseline\"\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "        baseline_predictions = [1] * self.df.shape[0]\n",
    "        self.base_acc = accuracy_score(self.df.labels, baseline_predictions)\n",
    "        self.base_rocauc = roc_auc_score(self.df.labels, baseline_predictions)\n",
    "        self.next(self.join)\n",
    "\n",
    "    @step\n",
    "    def train(self):\n",
    "        \"Train the model\"\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.keras.utils import set_random_seed\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        from model import get_model\n",
    "        set_random_seed(2022)\n",
    "        \n",
    "        self.cv = CountVectorizer(min_df=.005, max_df = .75, stop_words='english', strip_accents='ascii', )\n",
    "        res = self.cv.fit_transform(self.df['review'])\n",
    "        self.model = get_model(len(self.cv.vocabulary_))\n",
    "        self.model.fit(x=res.toarray(), \n",
    "                       y=self.df['labels'],\n",
    "                       batch_size=32, epochs=10, validation_split=.2)\n",
    "\n",
    "        self.next(self.join)\n",
    "        \n",
    "    @step\n",
    "    def join(self, inputs):\n",
    "        \"Compare the model results with the baseline.\"\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.keras import layers, optimizers, regularizers\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        import pandas as pd\n",
    "        \n",
    "        \n",
    "        self.model = inputs.train.model\n",
    "        self.cv = inputs.train.cv\n",
    "        self.train_df = inputs.train.df\n",
    "        self.holdout_df = pd.read_parquet('holdout.parquet')\n",
    "        \n",
    "        self.predictions = self.model.predict(self.cv.transform(self.holdout_df['review']).toarray())\n",
    "        labels = self.holdout_df['labels']\n",
    "        \n",
    "        self.model_acc = accuracy_score(labels, self.predictions > .5)\n",
    "        self.model_rocauc = roc_auc_score(labels, self.predictions)\n",
    "        \n",
    "        print(f'Baseline Acccuracy: {inputs.baseline.base_acc:.2%}')\n",
    "        print(f'Baseline AUC: {inputs.baseline.base_rocauc:.2}')\n",
    "        print(f'Model Acccuracy: {self.model_acc:.2%}')\n",
    "        print(f'Model AUC: {self.model_rocauc:.2}')\n",
    "        self.beats_baseline = self.model_rocauc > inputs.baseline.base_rocauc\n",
    "        print(f'Model beats baseline (T/F): {self.beats_baseline}')\n",
    "        \n",
    "        #smoke test to make sure model is doing the right thing on obvious examples.\n",
    "        _tst_reviews = [\"poor fit its baggy in places where it isn't supposed to be.\",\n",
    "                        \"love it, very high quality and great value\"]\n",
    "        _tst_preds = self.model.predict(self.cv.transform(_tst_reviews).toarray())\n",
    "        self.passed_smoke_test = _tst_preds[0][0] < .5 and _tst_preds[1][0] > .5\n",
    "        print(f'Model passed smoke test (T/F): {self.passed_smoke_test}')\n",
    "        \n",
    "        if self.beats_baseline and self.passed_smoke_test:\n",
    "            run = Flow(current.flow_name)[current.run_id]\n",
    "            run.add_tag('deployment_candidate')\n",
    "        self.next(self.end)\n",
    "        \n",
    "    @step\n",
    "    def end(self): ...\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MyFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d84c0-f9a0-4d30-b2e9-464178830548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.7.1\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mMyFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:hamel\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:03.867 \u001b[0m\u001b[1mWorkflow starting (run-id 1658296863862787):\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:03.876 \u001b[0m\u001b[32m[1658296863862787/start/1 (pid 29926)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:04.909 \u001b[0m\u001b[32m[1658296863862787/start/1 (pid 29926)] \u001b[0m\u001b[22mnum of rows: 20377\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:05.013 \u001b[0m\u001b[32m[1658296863862787/start/1 (pid 29926)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:05.023 \u001b[0m\u001b[32m[1658296863862787/baseline/2 (pid 29931)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:05.032 \u001b[0m\u001b[32m[1658296863862787/train/3 (pid 29932)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:06.442 \u001b[0m\u001b[32m[1658296863862787/baseline/2 (pid 29931)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:08.339 \u001b[0m\u001b[32m[1658296863862787/train/3 (pid 29932)] \u001b[0m\u001b[22m2022-07-19 23:01:08.339044: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:08.421 \u001b[0m\u001b[32m[1658296863862787/train/3 (pid 29932)] \u001b[0m\u001b[22mEpoch 1/10\u001b[0m\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.3523 - accuracy: 0.8507 - val_loss: 0.2988 - val_accuracy: 0.8754\u001b[0m53 - loss: 0.6811 - accuracy: 0.62\n",
      "\u001b[35m2022-07-19 23:01:09.284 \u001b[0m\u001b[32m[1658296863862787/train/3 (pid 29932)] \u001b[0m\u001b[22mEpoch 2/10\u001b[0m\n",
      "510/510 [==============================] - 0s 958us/step - loss: 0.2945 - accuracy: 0.8818 - val_loss: 0.2956 - val_accuracy: 0.8771\u001b[0m loss: 0.2944 - accuracy: 0.90\n",
      "\u001b[35m2022-07-19 23:01:09.773 \u001b[0m\u001b[32m[1658296863862787/train/3 (pid 29932)] \u001b[0m\u001b[22mEpoch 3/10\u001b[0m\n",
      "510/510 [==============================] - 0s 956us/step - loss: 0.2860 - accuracy: 0.8840 - val_loss: 0.2989 - val_accuracy: 0.8768\u001b[0m loss: 0.2319 - accuracy: 0.96\n",
      "\u001b[35m2022-07-19 23:01:10.261 \u001b[0m\u001b[32m[1658296863862787/train/3 (pid 29932)] \u001b[0m\u001b[22mEpoch 4/10\u001b[0m\n",
      "510/510 [==============================] - 0s 954us/step - loss: 0.2761 - accuracy: 0.8891 - val_loss: 0.2951 - val_accuracy: 0.8803\u001b[0m loss: 0.3847 - accuracy: 0.81\n",
      "\u001b[35m2022-07-19 23:01:10.748 \u001b[0m\u001b[32m[1658296863862787/train/3 (pid 29932)] \u001b[0m\u001b[22mEpoch 5/10\u001b[0m\n",
      "510/510 [==============================] - 0s 954us/step - loss: 0.2676 - accuracy: 0.8956 - val_loss: 0.2991 - val_accuracy: 0.8759\u001b[0m loss: 0.2714 - accuracy: 0.9\n",
      "\u001b[35m2022-07-19 23:01:11.235 \u001b[0m\u001b[32m[1658296863862787/train/3 (pid 29932)] \u001b[0m\u001b[22mEpoch 6/10\u001b[0m\n",
      "510/510 [==============================] - 0s 949us/step - loss: 0.2623 - accuracy: 0.9005 - val_loss: 0.2996 - val_accuracy: 0.8793\u001b[0m loss: 0.3324 - accuracy: 0.84\n",
      "\u001b[35m2022-07-19 23:01:11.720 \u001b[0m\u001b[32m[1658296863862787/train/3 (pid 29932)] \u001b[0m\u001b[22mEpoch 7/10\u001b[0m\n",
      "510/510 [==============================] - 0s 947us/step - loss: 0.2549 - accuracy: 0.9056 - val_loss: 0.3044 - val_accuracy: 0.8754\u001b[0m loss: 0.2044 - accuracy: 0.93\n",
      "\u001b[35m2022-07-19 23:01:12.203 \u001b[0m\u001b[32m[1658296863862787/train/3 (pid 29932)] \u001b[0m\u001b[22mEpoch 8/10\u001b[0m\n",
      "510/510 [==============================] - 0s 957us/step - loss: 0.2472 - accuracy: 0.9109 - val_loss: 0.3137 - val_accuracy: 0.8759\u001b[0m loss: 0.2832 - accuracy: 0.84\n",
      "\u001b[35m2022-07-19 23:01:12.691 \u001b[0m\u001b[32m[1658296863862787/train/3 (pid 29932)] \u001b[0m\u001b[22mEpoch 9/10\u001b[0m\n",
      "510/510 [==============================] - 0s 971us/step - loss: 0.2376 - accuracy: 0.9134 - val_loss: 0.3151 - val_accuracy: 0.8776\u001b[0m loss: 0.2699 - accuracy: 0.93\n",
      "\u001b[35m2022-07-19 23:01:13.187 \u001b[0m\u001b[32m[1658296863862787/train/3 (pid 29932)] \u001b[0m\u001b[22mEpoch 10/10\u001b[0m\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2298 - accuracy: 0.9187 - val_loss: 0.3276 - val_accuracy: 0.8744\u001b[0m - loss: 0.1719 - accuracy: 0.93\n",
      "\u001b[35m2022-07-19 23:01:13.846 \u001b[0m\u001b[32m[1658296863862787/train/3 (pid 29932)] \u001b[0m\u001b[22mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:13.847 \u001b[0m\u001b[32m[1658296863862787/train/3 (pid 29932)] \u001b[0m\u001b[22m2022-07-19 23:01:13.846758: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:13.876 \u001b[0m\u001b[32m[1658296863862787/train/3 (pid 29932)] \u001b[0m\u001b[22mWARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:14.384 \u001b[0m\u001b[32m[1658296863862787/train/3 (pid 29932)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:14.395 \u001b[0m\u001b[32m[1658296863862787/join/4 (pid 29940)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:16.806 \u001b[0m\u001b[32m[1658296863862787/join/4 (pid 29940)] \u001b[0m\u001b[22m2022-07-19 23:01:16.806559: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:17.227 \u001b[0m\u001b[32m[1658296863862787/join/4 (pid 29940)] \u001b[0m\u001b[22mBaseline Acccuracy: 77.04%\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:17.228 \u001b[0m\u001b[32m[1658296863862787/join/4 (pid 29940)] \u001b[0m\u001b[22mBaseline AUC: 0.5\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:17.251 \u001b[0m\u001b[32m[1658296863862787/join/4 (pid 29940)] \u001b[0m\u001b[22mModel Acccuracy: 87.77%\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:17.251 \u001b[0m\u001b[32m[1658296863862787/join/4 (pid 29940)] \u001b[0m\u001b[22mModel AUC: 0.91\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:17.251 \u001b[0m\u001b[32m[1658296863862787/join/4 (pid 29940)] \u001b[0m\u001b[22mModel beats baseline (T/F): True\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:17.251 \u001b[0m\u001b[32m[1658296863862787/join/4 (pid 29940)] \u001b[0m\u001b[22mModel passed smoke test (T/F): True\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:17.406 \u001b[0m\u001b[32m[1658296863862787/join/4 (pid 29940)] \u001b[0m\u001b[22mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:17.406 \u001b[0m\u001b[32m[1658296863862787/join/4 (pid 29940)] \u001b[0m\u001b[22m2022-07-19 23:01:17.405995: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:17.434 \u001b[0m\u001b[32m[1658296863862787/join/4 (pid 29940)] \u001b[0m\u001b[22mWARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:17.865 \u001b[0m\u001b[32m[1658296863862787/join/4 (pid 29940)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:17.877 \u001b[0m\u001b[32m[1658296863862787/end/5 (pid 29944)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:18.633 \u001b[0m\u001b[32m[1658296863862787/end/5 (pid 29944)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-19 23:01:18.633 \u001b[0m\u001b[1mDone!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "!python flow.py --no-pylint run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e9894f-a4fb-424b-aa08-f981760ef9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
