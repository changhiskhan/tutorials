{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d8c49a7a-e52b-42c7-bdaf-7d7db37e0b12",
   "metadata": {},
   "source": [
    "---\n",
    "title: Text Classification With Keras and Scikit-Learn\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0e5368-de92-43e6-b185-04bb897e929f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Background\n",
    "\n",
    "We are going to build a model that does classifies customer reviews as positive or negative sentiment, using the [Women's E-Commerce Clothing Reviews Dataset](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews). Here is what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57e959f3-7d68-4308-90a1-2c74d61e583b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of rows: 20377\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('train.parquet')\n",
    "print(f'num of rows: {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73aa7753-0530-4d93-8979-a8c7d9211343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Odd fit: I wanted to love this sweater but the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Very comfy dress: The quality and material of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Fits nicely but fabric a bit thin: I ordered t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Great fit: Love these jeans, fit and style... ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Stretches out, washes poorly. wish i could ret...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                             review\n",
       "0       0  Odd fit: I wanted to love this sweater but the...\n",
       "1       1  Very comfy dress: The quality and material of ...\n",
       "2       0  Fits nicely but fabric a bit thin: I ordered t...\n",
       "3       1  Great fit: Love these jeans, fit and style... ...\n",
       "4       0  Stretches out, washes poorly. wish i could ret..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66994bb8-b3c4-449f-b0bb-f5b56e021cf2",
   "metadata": {
    "tags": []
   },
   "source": [
    " We will walk you through how we would organize this task in Metaflow.  Concretely, we will demonstrate the following steps:\n",
    "\n",
    "1. **Read data from a parquet file** in the `start` step.\n",
    "2. **Show a branching workflow to record a baseline and train a model in parallel**  in the `baseline` and `train` steps.\n",
    "3. **Evaluate The Model** in the `join` step:\n",
    "    - on a holdout set and compare against the baseline\n",
    "    - do a smaoke test\n",
    "4. **If the model passes those it is tagged as a `deployment_candidate`** in the `end` step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e372da2-95d6-4be3-a47e-c676ba7ee18f",
   "metadata": {},
   "source": [
    "## Constructing The Metaflow Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75e3b107-901e-46b2-8db0-90846edd261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile flow.py\n",
    "\n",
    "from metaflow import FlowSpec, step, Flow, current\n",
    "\n",
    "class NLPFlow(FlowSpec):\n",
    "        \n",
    "    @step\n",
    "    def start(self):\n",
    "        \"Read the data\"\n",
    "        import pandas as pd\n",
    "        self.df = pd.read_parquet('train.parquet')\n",
    "        print(f'num of rows: {self.df.shape[0]}')\n",
    "        self.next(self.baseline, self.train)\n",
    "\n",
    "    @step\n",
    "    def baseline(self):\n",
    "        \"Compute the baseline\"\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "        baseline_predictions = [1] * self.df.shape[0]\n",
    "        self.base_acc = accuracy_score(self.df.labels, baseline_predictions)\n",
    "        self.base_rocauc = roc_auc_score(self.df.labels, baseline_predictions)\n",
    "        self.next(self.join)\n",
    "\n",
    "    @step\n",
    "    def train(self):\n",
    "        \"Train the model\"\n",
    "        from model import Nbow_Model\n",
    "        model = Nbow_Model(vocab_sz=750)\n",
    "        model.fit(X=self.df['review'], y=self.df['labels'])\n",
    "        self.model_dict = model.model_dict #save model\n",
    "        self.next(self.join)\n",
    "        \n",
    "    @step\n",
    "    def join(self, inputs):\n",
    "        \"Compare the model results with the baseline.\"\n",
    "        import pandas as pd\n",
    "        from model import Nbow_Model\n",
    "        self.model_dict = inputs.train.model_dict\n",
    "        self.train_df = inputs.train.df\n",
    "        self.holdout_df = pd.read_parquet('holdout.parquet')\n",
    "        model = Nbow_Model.from_dict(self.model_dict)\n",
    "        \n",
    "        self.model_acc = model.eval_acc(X=self.holdout_df['review'], labels=self.holdout_df['labels'])\n",
    "        self.model_rocauc = model.eval_rocauc(X=self.holdout_df['review'], labels=self.holdout_df['labels'])\n",
    "        \n",
    "        print(f'Baseline Acccuracy: {inputs.baseline.base_acc:.2%}')\n",
    "        print(f'Baseline AUC: {inputs.baseline.base_rocauc:.2}')\n",
    "        print(f'Model Acccuracy: {self.model_acc:.2%}')\n",
    "        print(f'Model AUC: {self.model_rocauc:.2}')\n",
    "        self.beats_baseline = self.model_rocauc > inputs.baseline.base_rocauc\n",
    "        print(f'Model beats baseline (T/F): {self.beats_baseline}')\n",
    "        \n",
    "        #smoke test to make sure model is doing the right thing on obvious examples.\n",
    "        _tst_reviews = [\"poor fit its baggy in places where it isn't supposed to be.\",\n",
    "                        \"love it, very high quality and great value\"]\n",
    "        _tst_preds = model.predict(_tst_reviews)\n",
    "        self.passed_smoke_test = _tst_preds[0][0] < .5 and _tst_preds[1][0] > .5\n",
    "        print(f'Model passed smoke test (T/F): {self.passed_smoke_test}')\n",
    "        self.next(self.end)\n",
    "        \n",
    "    @step\n",
    "    def end(self):\n",
    "        \"Tags model as a deployment candidate if it beats the baseline and passes smoke tests.\"\n",
    "        if self.beats_baseline and self.passed_smoke_test:\n",
    "            run = Flow(current.flow_name)[current.run_id]\n",
    "            run.add_tag('deployment_candidate')\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    NLPFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd4d84c0-f9a0-4d30-b2e9-464178830548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.7.1\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mNLPFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:hamel\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:07.534 \u001b[0m\u001b[1mWorkflow starting (run-id 1658348347529456):\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:07.544 \u001b[0m\u001b[32m[1658348347529456/start/1 (pid 39061)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:08.462 \u001b[0m\u001b[32m[1658348347529456/start/1 (pid 39061)] \u001b[0m\u001b[22mnum of rows: 20377\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:08.569 \u001b[0m\u001b[32m[1658348347529456/start/1 (pid 39061)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:08.579 \u001b[0m\u001b[32m[1658348347529456/baseline/2 (pid 39066)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:08.588 \u001b[0m\u001b[32m[1658348347529456/train/3 (pid 39067)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:09.945 \u001b[0m\u001b[32m[1658348347529456/baseline/2 (pid 39066)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:11.093 \u001b[0m\u001b[32m[1658348347529456/train/3 (pid 39067)] \u001b[0m\u001b[22m2022-07-20 13:19:11.093807: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:11.774 \u001b[0m\u001b[32m[1658348347529456/train/3 (pid 39067)] \u001b[0m\u001b[22mEpoch 1/10\u001b[0m\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.3520 - accuracy: 0.8503 - val_loss: 0.3026 - val_accuracy: 0.8685\u001b[0m23 - loss: 0.6820 - accuracy: 0.53\n",
      "\u001b[35m2022-07-20 13:19:12.653 \u001b[0m\u001b[32m[1658348347529456/train/3 (pid 39067)] \u001b[0m\u001b[22mEpoch 2/10\u001b[0m\n",
      "510/510 [==============================] - 0s 973us/step - loss: 0.2951 - accuracy: 0.8793 - val_loss: 0.2956 - val_accuracy: 0.8746\u001b[0m loss: 0.2287 - accuracy: 0.96\n",
      "\u001b[35m2022-07-20 13:19:13.149 \u001b[0m\u001b[32m[1658348347529456/train/3 (pid 39067)] \u001b[0m\u001b[22mEpoch 3/10\u001b[0m\n",
      "510/510 [==============================] - 0s 952us/step - loss: 0.2870 - accuracy: 0.8858 - val_loss: 0.2931 - val_accuracy: 0.8776\u001b[0m loss: 0.1956 - accuracy: 0.96\n",
      "\u001b[35m2022-07-20 13:19:13.636 \u001b[0m\u001b[32m[1658348347529456/train/3 (pid 39067)] \u001b[0m\u001b[22mEpoch 4/10\u001b[0m\n",
      "510/510 [==============================] - 0s 962us/step - loss: 0.2738 - accuracy: 0.8931 - val_loss: 0.2976 - val_accuracy: 0.8741\u001b[0m loss: 0.2466 - accuracy: 0.93\n",
      "\u001b[35m2022-07-20 13:19:14.127 \u001b[0m\u001b[32m[1658348347529456/train/3 (pid 39067)] \u001b[0m\u001b[22mEpoch 5/10\u001b[0m\n",
      "510/510 [==============================] - 0s 951us/step - loss: 0.2684 - accuracy: 0.8954 - val_loss: 0.2970 - val_accuracy: 0.8766\u001b[0m loss: 0.2306 - accuracy: 0.90\n",
      "\u001b[35m2022-07-20 13:19:14.612 \u001b[0m\u001b[32m[1658348347529456/train/3 (pid 39067)] \u001b[0m\u001b[22mEpoch 6/10\u001b[0m\n",
      "510/510 [==============================] - 0s 952us/step - loss: 0.2577 - accuracy: 0.8995 - val_loss: 0.3041 - val_accuracy: 0.8783\u001b[0m loss: 0.2238 - accuracy: 0.96\n",
      "\u001b[35m2022-07-20 13:19:15.098 \u001b[0m\u001b[32m[1658348347529456/train/3 (pid 39067)] \u001b[0m\u001b[22mEpoch 7/10\u001b[0m\n",
      "510/510 [==============================] - 1s 1ms/step - loss: 0.2513 - accuracy: 0.9050 - val_loss: 0.3079 - val_accuracy: 0.8786\u001b[0m - loss: 0.1824 - accuracy: 0.9\n",
      "\u001b[35m2022-07-20 13:19:15.615 \u001b[0m\u001b[32m[1658348347529456/train/3 (pid 39067)] \u001b[0m\u001b[22mEpoch 8/10\u001b[0m\n",
      "510/510 [==============================] - 1s 989us/step - loss: 0.2403 - accuracy: 0.9125 - val_loss: 0.3175 - val_accuracy: 0.8808\u001b[0m loss: 0.2413 - accuracy: 0.90\n",
      "\u001b[35m2022-07-20 13:19:16.120 \u001b[0m\u001b[32m[1658348347529456/train/3 (pid 39067)] \u001b[0m\u001b[22mEpoch 9/10\u001b[0m\n",
      "510/510 [==============================] - 0s 971us/step - loss: 0.2324 - accuracy: 0.9179 - val_loss: 0.3270 - val_accuracy: 0.8746\u001b[0m loss: 0.2396 - accuracy: 0.93\n",
      "\u001b[35m2022-07-20 13:19:16.616 \u001b[0m\u001b[32m[1658348347529456/train/3 (pid 39067)] \u001b[0m\u001b[22mEpoch 10/10\u001b[0m\n",
      "510/510 [==============================] - 0s 961us/step - loss: 0.2216 - accuracy: 0.9243 - val_loss: 0.3302 - val_accuracy: 0.8776\u001b[0m loss: 0.2485 - accuracy: 0.90\n",
      "\u001b[35m2022-07-20 13:19:17.233 \u001b[0m\u001b[32m[1658348347529456/train/3 (pid 39067)] \u001b[0m\u001b[22mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:17.233 \u001b[0m\u001b[32m[1658348347529456/train/3 (pid 39067)] \u001b[0m\u001b[22m2022-07-20 13:19:17.233244: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:17.260 \u001b[0m\u001b[32m[1658348347529456/train/3 (pid 39067)] \u001b[0m\u001b[22mWARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:17.757 \u001b[0m\u001b[32m[1658348347529456/train/3 (pid 39067)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:17.768 \u001b[0m\u001b[32m[1658348347529456/join/4 (pid 39077)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:20.294 \u001b[0m\u001b[32m[1658348347529456/join/4 (pid 39077)] \u001b[0m\u001b[22m2022-07-20 13:19:20.294051: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:20.843 \u001b[0m\u001b[32m[1658348347529456/join/4 (pid 39077)] \u001b[0m\u001b[22mBaseline Acccuracy: 77.04%\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:20.843 \u001b[0m\u001b[32m[1658348347529456/join/4 (pid 39077)] \u001b[0m\u001b[22mBaseline AUC: 0.5\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:20.864 \u001b[0m\u001b[32m[1658348347529456/join/4 (pid 39077)] \u001b[0m\u001b[22mModel Acccuracy: 87.63%\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:20.864 \u001b[0m\u001b[32m[1658348347529456/join/4 (pid 39077)] \u001b[0m\u001b[22mModel AUC: 0.92\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:20.864 \u001b[0m\u001b[32m[1658348347529456/join/4 (pid 39077)] \u001b[0m\u001b[22mModel beats baseline (T/F): True\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:20.864 \u001b[0m\u001b[32m[1658348347529456/join/4 (pid 39077)] \u001b[0m\u001b[22mModel passed smoke test (T/F): True\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:21.007 \u001b[0m\u001b[32m[1658348347529456/join/4 (pid 39077)] \u001b[0m\u001b[22mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:21.007 \u001b[0m\u001b[32m[1658348347529456/join/4 (pid 39077)] \u001b[0m\u001b[22m2022-07-20 13:19:21.006958: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:21.035 \u001b[0m\u001b[32m[1658348347529456/join/4 (pid 39077)] \u001b[0m\u001b[22mWARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:21.498 \u001b[0m\u001b[32m[1658348347529456/join/4 (pid 39077)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:21.507 \u001b[0m\u001b[32m[1658348347529456/end/5 (pid 39082)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:22.377 \u001b[0m\u001b[32m[1658348347529456/end/5 (pid 39082)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:22.378 \u001b[0m\u001b[1mDone!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "!python flow.py --no-pylint run "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef18b4e-6d46-4219-9329-6c7ffd89d55e",
   "metadata": {},
   "source": [
    "## Using The Model In Production\n",
    "\n",
    "After you have trained a model in Metaflow, you may want to utilize this model to make predictions or for futher testing.  There are two common patterns for this: (1) Retrieve the model from Metaflow in an external system (2) Have another flow that does predictions.  We illustrate both examples here:\n",
    "\n",
    "### 1. Retrieve Model From Metaflow To Use In External Systems\n",
    "\n",
    "You can now retrieve the model tagged as a `deployment_candidate` outside Metaflow, so you can use this in whatever downstream application you want, or even just for ad-hoc testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0e9894f-a4fb-424b-aa08-f981760ef9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import Flow\n",
    "import pandas as pd\n",
    "from model import Nbow_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b34b744-225b-490a-8fb8-a76bcdc1f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pd.read_parquet('predict.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f3b56b-292b-441f-9b1a-e5edb149866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_successful_run(flow_nm, tag):\n",
    "    \"Gets the latest successfull run for a flow with a specific tag.\"\n",
    "    for r in Flow(flow_nm).runs(tag):\n",
    "        if r.successful: return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e62b2f3-9a75-4d00-8df8-635c955cc4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-20 13:19:24.702377: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "run = get_latest_successful_run('NLPFlow', 'deployment_candidate')\n",
    "model = Nbow_Model.from_dict(run.data.model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "902f5d50-8490-4f70-b3ee-79316965851f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9995303 ],\n",
       "       [0.9741467 ],\n",
       "       [0.9999521 ],\n",
       "       ...,\n",
       "       [0.9997336 ],\n",
       "       [0.99905205],\n",
       "       [0.70124   ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(predict_df['review'])\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7765d5-7b22-4fef-94a1-5e688af8d358",
   "metadata": {},
   "source": [
    "You can write these predictions to a parquet file like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06ce452f-6ec2-4cba-b074-7c8a929d331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "pa_tbl = pa.table({\"data\": preds.squeeze()})\n",
    "pa.parquet.write_table(pa_tbl, \"sentiment_predictions.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a8580-dcb6-4d1c-8442-1c21eacf91d4",
   "metadata": {},
   "source": [
    "### 2. Use a Flow To Make Predictions\n",
    "\n",
    "You may want to do batch predictions in a Flow as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbc83ba1-988f-4ca2-9a19-467806308dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting predflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predflow.py\n",
    "\n",
    "from metaflow import FlowSpec, step, Flow, current\n",
    "\n",
    "class NLPredictionFlow(FlowSpec):\n",
    "    \n",
    "    def get_latest_successful_run(self, flow_nm, tag):\n",
    "        \"Gets the latest successfull run for a flow with a specific tag.\"\n",
    "        for r in Flow(flow_nm).runs(tag):\n",
    "            if r.successful: return r\n",
    "        \n",
    "    @step\n",
    "    def start(self):\n",
    "        \"Get the latest deployment candidate that is from a successfull run\"\n",
    "        self.deploy_run = self.get_latest_successful_run('NLPFlow', 'deployment_candidate')\n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        \"Make predictions\"\n",
    "        from model import Nbow_Model\n",
    "        import pandas as pd\n",
    "        import pyarrow as pa\n",
    "        new_reviews = pd.read_parquet('predict.parquet')['review']\n",
    "        \n",
    "        # Make predictions\n",
    "        model = Nbow_Model.from_dict(self.deploy_run.data.model_dict)\n",
    "        predictions = model.predict(new_reviews)\n",
    "        print(f'Writing predictions to parquet: {predictions.shape[0]:,} rows')\n",
    "        pa_tbl = pa.table({\"data\": predictions.squeeze()})\n",
    "        pa.parquet.write_table(pa_tbl, \"sentiment_predictions.parquet\")\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    NLPredictionFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17b6269d-f70b-41d5-b9ee-363263506e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.7.1\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mNLPredictionFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:hamel\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:26.426 \u001b[0m\u001b[1mWorkflow starting (run-id 1658348366422276):\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:26.436 \u001b[0m\u001b[32m[1658348366422276/start/1 (pid 39093)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:27.239 \u001b[0m\u001b[32m[1658348366422276/start/1 (pid 39093)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:27.249 \u001b[0m\u001b[32m[1658348366422276/end/2 (pid 39097)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:29.761 \u001b[0m\u001b[32m[1658348366422276/end/2 (pid 39097)] \u001b[0m\u001b[22m2022-07-20 13:19:29.761103: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:30.116 \u001b[0m\u001b[32m[1658348366422276/end/2 (pid 39097)] \u001b[0m\u001b[22mWriting predictions to parquet: 2,264 rows\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:30.402 \u001b[0m\u001b[32m[1658348366422276/end/2 (pid 39097)] \u001b[0m\u001b[22mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:30.404 \u001b[0m\u001b[32m[1658348366422276/end/2 (pid 39097)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-20 13:19:30.404 \u001b[0m\u001b[1mDone!\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python predflow.py run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb4d363-ecbb-4784-8c50-6c61c36a164f",
   "metadata": {},
   "source": [
    "### Further Discussion\n",
    "\n",
    "This is a very simple example that will also run on your laptop.  However, for production use cases you may want to use [@conda](https://docs.metaflow.org/metaflow/dependencies#managing-dependencies-with-conda-decorator) for dependency management, [@batch](https://docs.metaflow.org/v/r/metaflow/scaling#using-aws-batch) or [@kubernetes](https://docs.metaflow.org/metaflow/scaling-out-and-up/effortless-scaling-with-kubernetes) for remote execution, and [@schedule](https://docs.metaflow.org/going-to-production-with-metaflow/scheduling-metaflow-flows/scheduling-with-aws-step-functions#scheduling-a-flow) to schedule jobs to run periodically.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
