{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f612476-9d5b-4fe3-8e71-182848880c94",
   "metadata": {},
   "source": [
    "# Lesson 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4949c93a-8c90-4835-9b67-0fb9926589d4",
   "metadata": {},
   "source": [
    "## Showcasing\n",
    "\n",
    "* Metaflow Fundamentals\n",
    "    * DAGs and `metaflow.FlowSpec`\n",
    "    * Decorators and `metaflow.step`\n",
    "* Running Flows\n",
    "    * RandomForestFlow\n",
    "    * GradientBoostedTreesFlow\n",
    "    * NeuralNetFlow\n",
    "* Analyzing Flows\n",
    "    * `metaflow.cards`\n",
    "    * Using the Client API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effc70a9-eff1-4d70-807c-ece4dde20d50",
   "metadata": {},
   "source": [
    "## Orchestrating ML Workflows with DAGs\n",
    "\n",
    "Short paragraph motivating DAGs and linking out to Hugo's CC post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be59c3c5-236b-4883-8436-f5f5395b54f3",
   "metadata": {},
   "source": [
    "## Building DAGs with Metaflow\n",
    "\n",
    "Metaflow is built to build ML DAGs blah blah. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f035f4f4-a827-4998-9473-56ac3df2b33a",
   "metadata": {},
   "source": [
    "### Metaflow Fundamentals\n",
    "\n",
    "One to two sentence value prop of each section under this H3. Progressively build up to full template flow by asking the user to add one element at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302f9187-2e0f-4626-aaab-9c18942b8f4d",
   "metadata": {},
   "source": [
    "#### Dags and FlowSpec\n",
    "\n",
    "Objects common to all flows. Here is minimal flow:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886e61c2-edac-4f28-bc5e-eda3cd4a6959",
   "metadata": {},
   "source": [
    "#### Decorators and steps\n",
    "\n",
    "How you talk to metaflow..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bac1255-8924-42ae-8e3e-ae4dadea17a4",
   "metadata": {},
   "source": [
    "#### Running Flows\n",
    "\n",
    "Show commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d32ca4-04dd-4b38-b0ac-3df964470b3b",
   "metadata": {},
   "source": [
    "#### Visualizing Results with Cards\n",
    "\n",
    "can track state of data in steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9fad48-fec4-481e-a7c9-c7da98fc733a",
   "metadata": {},
   "source": [
    "#### Flow Analysis with Metaflow Client API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837f3813-9c7a-48a0-a43c-6ea3daae9637",
   "metadata": {},
   "source": [
    "### Random Forest Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b4f7f63-c19b-40b7-beeb-49ba4e623f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting random_forest_flow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile random_forest_flow.py\n",
    "from metaflow import FlowSpec, step, Parameter\n",
    "\n",
    "class RandomForestFlow(FlowSpec):\n",
    "    \n",
    "    test_size = Parameter(\"test_size\", default=0.2)\n",
    "    random_state = Parameter(\"random_state\", default=42)\n",
    "    n_estimators = Parameter(\"n_estimators\", default=10)\n",
    "    min_samples_split = Parameter(\"min_samples_split\", default=2)\n",
    "    \n",
    "    @step\n",
    "    def start(self):\n",
    "        from sklearn import datasets\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        iris = datasets.load_iris()\n",
    "        self.X = iris['data']\n",
    "        self.y = iris['target']\n",
    "        data = train_test_split(self.X, self.y, \n",
    "                                test_size=self.test_size, \n",
    "                                random_state=self.random_state)\n",
    "        self.X_train = data[0]\n",
    "        self.X_test = data[1]\n",
    "        self.y_train = data[2]\n",
    "        self.y_test = data[3]\n",
    "        self.next(self.train)\n",
    "        \n",
    "    @step\n",
    "    def train(self):\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        self.clf = RandomForestClassifier(n_estimators=self.n_estimators,\n",
    "                                          min_samples_split=self.min_samples_split, \n",
    "                                          random_state=self.random_state)\n",
    "        self.clf.fit(self.X_train, self.y_train)\n",
    "        self.next(self.score)\n",
    "\n",
    "    @step\n",
    "    def score(self):\n",
    "        self.accuracy = self.clf.score(self.X_test, self.y_test)\n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        print(\"Random Forest Model Accuracy: {}%\".format(round(100*self.accuracy, 3)))\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    RandomForestFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18b6e9c4-ea54-4a84-aab9-c70c4feb33a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.7.1\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mRandomForestFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:eddie\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-07-21 08:35:27.537 \u001b[0m\u001b[1mWorkflow starting (run-id 1658410527532180):\u001b[0m\n",
      "\u001b[35m2022-07-21 08:35:27.546 \u001b[0m\u001b[32m[1658410527532180/start/1 (pid 50580)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-21 08:35:28.398 \u001b[0m\u001b[32m[1658410527532180/start/1 (pid 50580)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-21 08:35:28.406 \u001b[0m\u001b[32m[1658410527532180/train/2 (pid 50583)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-21 08:35:29.168 \u001b[0m\u001b[32m[1658410527532180/train/2 (pid 50583)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-21 08:35:29.176 \u001b[0m\u001b[32m[1658410527532180/score/3 (pid 50586)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-21 08:35:29.923 \u001b[0m\u001b[32m[1658410527532180/score/3 (pid 50586)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-21 08:35:29.931 \u001b[0m\u001b[32m[1658410527532180/end/4 (pid 50589)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-21 08:35:30.299 \u001b[0m\u001b[32m[1658410527532180/end/4 (pid 50589)] \u001b[0m\u001b[22mRandom Forest Model Accuracy: 96.667%\u001b[0m\n",
      "\u001b[35m2022-07-21 08:35:30.352 \u001b[0m\u001b[32m[1658410527532180/end/4 (pid 50589)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-21 08:35:30.353 \u001b[0m\u001b[1mDone!\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python random_forest_flow.py run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2236b479-6c55-426e-80e0-ff60169788a8",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3118ef48-b730-4f95-ab4b-e963e2fed7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gradient_boosted_trees_flow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gradient_boosted_trees_flow.py\n",
    "\n",
    "from metaflow import FlowSpec, step, Parameter\n",
    "\n",
    "class GradientBoostedTreesFlow(FlowSpec):\n",
    "    \n",
    "    test_size = Parameter(\"test_size\", default=0.2)\n",
    "    random_state = Parameter(\"random_state\", default=42)\n",
    "    n_estimators = Parameter(\"n_estimators\", default=10)\n",
    "    eval_metric = Parameter(\"eval_metric\", default='mlogloss')\n",
    "    \n",
    "    @step\n",
    "    def start(self):\n",
    "        from sklearn import datasets\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        iris = datasets.load_iris()\n",
    "        self.X = iris['data']\n",
    "        self.y = iris['target']\n",
    "        data = train_test_split(self.X, self.y, \n",
    "                                test_size=self.test_size, \n",
    "                                random_state=self.random_state)\n",
    "        self.X_train = data[0]\n",
    "        self.X_test = data[1]\n",
    "        self.y_train = data[2]\n",
    "        self.y_test = data[3]\n",
    "        self.next(self.train)\n",
    "        \n",
    "    @step\n",
    "    def train(self):\n",
    "        from xgboost import XGBClassifier\n",
    "        self.clf = XGBClassifier(n_estimators=self.n_estimators,\n",
    "                                 random_state=self.random_state,\n",
    "                                 eval_metric=self.eval_metric,\n",
    "                                 use_label_encoder=False)\n",
    "        self.clf.fit(self.X_train, self.y_train)\n",
    "        self.next(self.score)\n",
    "\n",
    "    @step\n",
    "    def score(self):\n",
    "        self.accuracy = self.clf.score(self.X_test, self.y_test)\n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        print(\"Gradient Boosted Trees Model Accuracy: {}%\".format(round(100*self.accuracy, 3)))\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    GradientBoostedTreesFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24cc7c8b-a002-41c2-98dc-3e16ced1af56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.7.1\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mGradientBoostedTreesFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:eddie\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-07-21 08:37:18.112 \u001b[0m\u001b[1mWorkflow starting (run-id 1658410638107504):\u001b[0m\n",
      "\u001b[35m2022-07-21 08:37:18.122 \u001b[0m\u001b[32m[1658410638107504/start/1 (pid 50625)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-21 08:37:18.959 \u001b[0m\u001b[32m[1658410638107504/start/1 (pid 50625)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-21 08:37:18.968 \u001b[0m\u001b[32m[1658410638107504/train/2 (pid 50628)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-21 08:37:20.010 \u001b[0m\u001b[32m[1658410638107504/train/2 (pid 50628)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-21 08:37:20.019 \u001b[0m\u001b[32m[1658410638107504/score/3 (pid 50631)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-21 08:37:20.969 \u001b[0m\u001b[32m[1658410638107504/score/3 (pid 50631)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-21 08:37:20.978 \u001b[0m\u001b[32m[1658410638107504/end/4 (pid 50634)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-21 08:37:21.344 \u001b[0m\u001b[32m[1658410638107504/end/4 (pid 50634)] \u001b[0m\u001b[22mGradient Boosted Trees Model Accuracy: 96.667%\u001b[0m\n",
      "\u001b[35m2022-07-21 08:37:21.400 \u001b[0m\u001b[32m[1658410638107504/end/4 (pid 50634)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-21 08:37:21.400 \u001b[0m\u001b[1mDone!\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python gradient_boosted_trees_flow.py run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f50f2c-cfe9-43e6-93b1-c7e25fdeaa6c",
   "metadata": {},
   "source": [
    "### Neural Net Flow\n",
    "\n",
    "Use card to show the feature distributions before and after scaling for `X_train` and `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61522d8a-e970-4de7-9c89-cbc8fa993237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting neural_net_flow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile neural_net_flow.py\n",
    "from metaflow import FlowSpec, step, Parameter, card, current\n",
    "from metaflow.cards import Image\n",
    "from tensorflow import keras\n",
    "\n",
    "def build_model(hidden_layer_dim, meta):\n",
    "    # meta is a scikeras argument that will be\n",
    "    # handed a dict containing input metadata\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    X_shape_ = meta[\"X_shape_\"]\n",
    "    n_classes_ = meta[\"n_classes_\"]\n",
    "\n",
    "    # build neural net model \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(n_features_in_, \n",
    "                                 input_shape=X_shape_[1:]))\n",
    "    model.add(keras.layers.Activation(\"relu\"))\n",
    "    model.add(keras.layers.Dense(hidden_layer_dim))\n",
    "    model.add(keras.layers.Activation(\"relu\"))\n",
    "    model.add(keras.layers.Dense(n_classes_))\n",
    "    model.add(keras.layers.Activation(\"softmax\"))\n",
    "    return model\n",
    "\n",
    "class NeuralNetFlow(FlowSpec):\n",
    "    \n",
    "    test_size = Parameter(\"test_size\", default=0.2)\n",
    "    random_state = Parameter(\"random_state\", default=42)\n",
    "    hidden_layer_dim = Parameter(\"hidden_layer_dim\", default=100)\n",
    "    epochs = Parameter(\"epochs\", default=200)\n",
    "    loss_fn = Parameter(\"loss_fn\", default='categorical_crossentropy')\n",
    "    \n",
    "    @step\n",
    "    def start(self):\n",
    "        from sklearn import datasets\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        self.iris = datasets.load_iris()\n",
    "        self.X = self.iris['data']\n",
    "        self.y = self.iris['target']\n",
    "        data = train_test_split(self.X, self.y, \n",
    "                                test_size=self.test_size, \n",
    "                                random_state=self.random_state)\n",
    "        self.X_train = data[0]\n",
    "        self.X_test = data[1]\n",
    "        self.y_train = data[2]\n",
    "        self.y_test = data[3]\n",
    "        self.next(self.scale_features)\n",
    "    \n",
    "    @card\n",
    "    @step\n",
    "    def scale_features(self):\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        self.X_train_scaled = scaler.fit_transform(self.X_train)\n",
    "        self.X_test_scaled = scaler.transform(self.X_test)\n",
    "        self.next(self.visualize_feature_distributions)\n",
    "        \n",
    "    @card()\n",
    "    @step\n",
    "    def visualize_feature_distributions(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        n_features = self.X_train.shape[1]\n",
    "        assert n_features == self.X_test.shape[1], \"Train and test feature dimensions are not the same!\"\n",
    "        feature_datasets = [self.X_train, self.X_train_scaled, self.X_test, self.X_test_scaled]\n",
    "        n_bins = 10\n",
    "        fig, axs = plt.subplots(len(feature_datasets), n_features, figsize=(16,16))\n",
    "        for i,data in enumerate(feature_datasets):\n",
    "            for j in range(n_features):\n",
    "                axs[i,j].hist(data[:, i], bins=n_bins)\n",
    "                axs[i,j].set_title(\"X train - {}\".format(self.iris['feature_names'][i]))\n",
    "        current.card.append(Image.from_matplotlib(fig))\n",
    "        self.next(self.train)\n",
    "        \n",
    "        \n",
    "    @step\n",
    "    def train(self):\n",
    "        from scikeras.wrappers import KerasClassifier\n",
    "        self.clf = KerasClassifier(build_model, \n",
    "                                   loss=self.loss_fn,\n",
    "                                   hidden_layer_dim=self.hidden_layer_dim,\n",
    "                                   epochs=self.epochs,\n",
    "                                   verbose=0)\n",
    "        self.clf.fit(self.X_train, self.y_train)\n",
    "        self.next(self.score)\n",
    "\n",
    "    @step\n",
    "    def score(self):\n",
    "        self.accuracy = self.clf.score(self.X_test, self.y_test)\n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        print(\"Neural Net Model Accuracy: {}%\".format(round(100*self.accuracy, 3)))\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    NeuralNetFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b904ed42-5965-42e7-a7e5-5331d824ab47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.7.1\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mNeuralNetFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:eddie\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:36.804 \u001b[0m\u001b[1mWorkflow starting (run-id 1658412816797829):\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:36.819 \u001b[0m\u001b[32m[1658412816797829/start/1 (pid 51723)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:39.289 \u001b[0m\u001b[32m[1658412816797829/start/1 (pid 51723)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:39.301 \u001b[0m\u001b[32m[1658412816797829/scale_features/2 (pid 51726)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:44.138 \u001b[0m\u001b[32m[1658412816797829/scale_features/2 (pid 51726)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:44.149 \u001b[0m\u001b[32m[1658412816797829/visualize_feature_distributions/3 (pid 51732)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:49.812 \u001b[0m\u001b[32m[1658412816797829/visualize_feature_distributions/3 (pid 51732)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:49.822 \u001b[0m\u001b[32m[1658412816797829/train/4 (pid 51738)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:51.913 \u001b[0m\u001b[32m[1658412816797829/train/4 (pid 51738)] \u001b[0m\u001b[22m2022-07-21 09:13:51.913396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:52.693 \u001b[0m\u001b[32m[1658412816797829/train/4 (pid 51738)] \u001b[0m\u001b[22mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:52.693 \u001b[0m\u001b[32m[1658412816797829/train/4 (pid 51738)] \u001b[0m\u001b[22m2022-07-21 09:13:52.693662: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:53.251 \u001b[0m\u001b[32m[1658412816797829/train/4 (pid 51738)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:53.261 \u001b[0m\u001b[32m[1658412816797829/score/5 (pid 51741)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:55.311 \u001b[0m\u001b[32m[1658412816797829/score/5 (pid 51741)] \u001b[0m\u001b[22m2022-07-21 09:13:55.311484: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:55.610 \u001b[0m\u001b[32m[1658412816797829/score/5 (pid 51741)] \u001b[0m\u001b[22mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:55.610 \u001b[0m\u001b[32m[1658412816797829/score/5 (pid 51741)] \u001b[0m\u001b[22m2022-07-21 09:13:55.610394: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:56.151 \u001b[0m\u001b[32m[1658412816797829/score/5 (pid 51741)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:56.163 \u001b[0m\u001b[32m[1658412816797829/end/6 (pid 51744)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:58.081 \u001b[0m\u001b[32m[1658412816797829/end/6 (pid 51744)] \u001b[0m\u001b[22mNeural Net Model Accuracy: 100.0%\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:58.349 \u001b[0m\u001b[32m[1658412816797829/end/6 (pid 51744)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-07-21 09:13:58.349 \u001b[0m\u001b[1mDone!\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python neural_net_flow.py run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99751661-283c-499f-8146-280f87f6e965",
   "metadata": {},
   "source": [
    "#### Visualize card created in `visualize_feature_distributions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dcf0e712-f607-4cce-8d7c-cf19d51eab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.7.1\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mNeuralNetFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:eddie\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22mResolving card: NeuralNetFlow/1658412816797829/visualize_feature_distributions/3\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python neural_net_flow.py card view visualize_feature_distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdd3c5c-7d5b-4fba-b60f-4851d210b631",
   "metadata": {},
   "source": [
    "### Analyze Flow Results Using Client API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd5a9128-ed7a-4a37-87c2-9b63d0791241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9666666666666667\n",
      "Gradient Boosted Trees Accuracy: 0.9666666666666667\n",
      "Neural Net Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from metaflow import Flow\n",
    "\n",
    "random_forest_data = Flow('RandomForestFlow').latest_successful_run.data\n",
    "gradient_boosted_trees_data = Flow('GradientBoostedTreesFlow').latest_successful_run.data\n",
    "neural_net_data = Flow('NeuralNetFlow').latest_successful_run.data\n",
    "\n",
    "for model_name, run_data in zip([\"Random Forest\", \"Gradient Boosted Trees\", \"Neural Net\"], \n",
    "                                [random_forest_data, gradient_boosted_trees_data, neural_net_data]):\n",
    "    print(\"{} Accuracy: {}\".format(model_name, run_data.accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48484798-8100-4e02-a827-cf7363a74299",
   "metadata": {},
   "source": [
    "#### Learn m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
